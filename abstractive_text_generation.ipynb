{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstractive_text_generation",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jain-harshil/Neural-Catchphrase-Generation/blob/master/abstractive_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3kMKCnMtM_8",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "https://github.com/aravindpai/How-to-build-own-text-summarizer-using-deep-learning/blob/master/How_to_build_own_text_summarizer_using_deep_learning.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL47PFhIpQTi",
        "colab_type": "text"
      },
      "source": [
        "Setting path for my files(dataset and activation.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-s-b9RxaGOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, '/content/drive/My Drive/NLP/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt6uAmh1VVPy",
        "colab_type": "code",
        "outputId": "555c9e65-06bf-47e0-c37a-111b2225c7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpF518YDoQIM",
        "colab_type": "text"
      },
      "source": [
        "## Custom Attention Layer\n",
        "\n",
        "attention.py is another python file.\n",
        "For prediction of words, the whole text is usually unecessary. AttentionLayer is used to extract those specific words from the text.\n",
        "Example: Which sport do you like?\n",
        "Ans: I love football.\n",
        "Here, I can be derived from you; love from like; and football from sport."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By6T-YGP7j6e",
        "colab_type": "code",
        "outputId": "75eb4d42-c763-486a-b443-52dacb68411c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "!pip install keras-self-attention"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.42.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.3.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htbaCjny6Zx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer\n",
        "from keras_self_attention import SeqSelfAttention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt6P3LUi9_HD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import random\n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRRV6jnn-OaM",
        "colab_type": "code",
        "outputId": "98a4fa21-17c0-4f97-a608-9475b9e1db0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sypKeqdpdMN",
        "colab_type": "text"
      },
      "source": [
        "# Reading and Preprocessing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-xSZgAk-UL9",
        "colab_type": "code",
        "outputId": "6e915509-5cf2-4b64-f9e7-e1f74b147e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/NLP/extracted_documents3.csv\")\n",
        "data.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Title</th>\n",
              "      <th>extracted_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joi...</td>\n",
              "      <td>Dual Recurrent Attention Units for Visual Question Answering</td>\n",
              "      <td>The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...</td>\n",
              "      <td>Sequential Short-Text Classification with Recurrent and Convolutional\\n  Neural Networks</td>\n",
              "      <td>Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a ...</td>\n",
              "      <td>Multiresolution Recurrent Neural Networks: An Application to Dialogue\\n  Response Generation</td>\n",
              "      <td>natural language tokens (word\\nperplexity), optimizing the joint log-likelihood biases the model towards\\nmodeling high-level abstractions. Finally, our experiments\\ndemonstrate that the proposed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related...</td>\n",
              "      <td>Learning what to share between loosely related tasks</td>\n",
              "      <td>In Natural Language Processing (NLP), it is hard to predict if\\nsharing will lead to improvements, particularly if tasks are only loosely\\nrelated. We perform\\nexperiments on three task pairs, and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of convers...</td>\n",
              "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
              "      <td>By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The syste...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                  Abstract  ...                                                                                                                                                                                           extracted_text\n",
              "0  We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joi...  ...  The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts ...\n",
              "1  Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...  ...  Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...\n",
              "2  We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a ...  ...  natural language tokens (word\\nperplexity), optimizing the joint log-likelihood biases the model towards\\nmodeling high-level abstractions. Finally, our experiments\\ndemonstrate that the proposed ...\n",
              "3  Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related...  ...  In Natural Language Processing (NLP), it is hard to predict if\\nsharing will lead to improvements, particularly if tasks are only loosely\\nrelated. We perform\\nexperiments on three task pairs, and...\n",
              "4  We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of convers...  ...  By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The syste...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u04ed2gq_wTM",
        "colab_type": "code",
        "outputId": "dd70b4d7-fa1c-4ddd-c807-4004722c7632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data = data.dropna()\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "data.shape"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61399, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXPawRWF__an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9bgXUxpAOxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=3:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in data['extracted_text']:\n",
        "    cleaned_text.append(text_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuFlmmYqAvD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    # tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_summary = []\n",
        "for t in data['Title']:\n",
        "    cleaned_summary.append(summary_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaXQHvx2BSCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PnqH2pQaLaF",
        "colab_type": "code",
        "outputId": "5835854c-71bf-4533-d178-21acf405449e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Title</th>\n",
              "      <th>extracted_text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joi...</td>\n",
              "      <td>Dual Recurrent Attention Units for Visual Question Answering</td>\n",
              "      <td>The memory characteristic of the\\nproposed recurrent attention units offers a rich joint embedding of visual and\\ntextual features and enables the model to reason relations between several\\nparts ...</td>\n",
              "      <td>memory characteristic proposed recurrent attention units offers rich joint embedding visual textual features enables model reason relations several parts image question also experiment replacing a...</td>\n",
              "      <td>dual recurrent attention units for visual question answering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...</td>\n",
              "      <td>Sequential Short-Text Classification with Recurrent and Convolutional\\n  Neural Networks</td>\n",
              "      <td>Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...</td>\n",
              "      <td>recent approaches based artificial neural networks shown promising results short text classification however many short texts occur sequences existing ann based systems leverage preceding short te...</td>\n",
              "      <td>sequential short text classification with recurrent and convolutional neural networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a ...</td>\n",
              "      <td>Multiresolution Recurrent Neural Networks: An Application to Dialogue\\n  Response Generation</td>\n",
              "      <td>natural language tokens (word\\nperplexity), optimizing the joint log-likelihood biases the model towards\\nmodeling high-level abstractions. Finally, our experiments\\ndemonstrate that the proposed ...</td>\n",
              "      <td>natural language tokens optimizing joint log likelihood biases model towards modeling high level abstractions finally experiments demonstrate proposed model adept overcoming sparsity natural langu...</td>\n",
              "      <td>multiresolution recurrent neural networks an application to dialogue response generation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related...</td>\n",
              "      <td>Learning what to share between loosely related tasks</td>\n",
              "      <td>In Natural Language Processing (NLP), it is hard to predict if\\nsharing will lead to improvements, particularly if tasks are only loosely\\nrelated. We perform\\nexperiments on three task pairs, and...</td>\n",
              "      <td>natural language processing hard predict sharing lead improvements particularly tasks loosely related perform experiments three task pairs across seven different domains using data ontonotes achie...</td>\n",
              "      <td>learning what to share between loosely related tasks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of convers...</td>\n",
              "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
              "      <td>By applying reinforcement learning to\\ncrowdsourced data and real-world user interactions, the system has been trained\\nto select an appropriate response from the models in its ensemble. The syste...</td>\n",
              "      <td>applying reinforcement learning crowdsourced data real world user interactions system trained select appropriate response models ensemble system evaluated testing real world users performed signif...</td>\n",
              "      <td>deep reinforcement learning chatbot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                  Abstract  ...                                                                            cleaned_summary\n",
              "0  We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joi...  ...                              dual recurrent attention units for visual question answering \n",
              "1  Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...  ...     sequential short text classification with recurrent and convolutional neural networks \n",
              "2  We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a ...  ...  multiresolution recurrent neural networks an application to dialogue response generation \n",
              "3  Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related...  ...                                      learning what to share between loosely related tasks \n",
              "4  We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of convers...  ...                                                       deep reinforcement learning chatbot \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zE5PrSuw5Xn",
        "colab_type": "code",
        "outputId": "11dbba00-050a-4d5e-8ec0-160a32b39328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61399"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoYtjxbSB2ew",
        "colab_type": "code",
        "outputId": "3dd5bbc7-5594-481f-c231-022ce949c5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "    \n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ZjkXCOLBQ7",
        "colab_type": "code",
        "outputId": "3e860c7e-7938-4801-f447-5efd7b612792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "count_len_text = 0\n",
        "for i in data['cleaned_summary']:\n",
        "  if(len(i.split())<15):\n",
        "    count_len_text += 1\n",
        "    \n",
        "print(count_len_text/len(data['cleaned_text']))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9456994413589798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-6wpPFVptNL",
        "colab_type": "text"
      },
      "source": [
        "94% of the dataset has titles which are less than 15 words. 92% of the dataset has extracted abstract with less than 100 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dey9P2cRCKBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_text_len=200\n",
        "max_summary_len=15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIinVDTmPRAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "org_text = np.array(data['Abstract'])\n",
        "org_title = np.array(data['Title'])\n",
        "cleaned_text =np.array(data['cleaned_text'])\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\n",
        "\n",
        "original_text = []\n",
        "original_title = []\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        original_text.append(org_text[i])\n",
        "        original_title.append(org_title[i])\n",
        "        \n",
        "        \n",
        "df=pd.DataFrame({'Abstract':original_text,'Title':original_title,'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWn38xuqp_uV",
        "colab_type": "text"
      },
      "source": [
        "sostok - start tag of title <br> estok - end tag of title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlIAR6K3Bjr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OkNI_yeBZor",
        "colab_type": "code",
        "outputId": "3d9a6690-7b63-476a-80e6-82f54cac0acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Title</th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joi...</td>\n",
              "      <td>Dual Recurrent Attention Units for Visual Question Answering</td>\n",
              "      <td>memory characteristic proposed recurrent attention units offers rich joint embedding visual textual features enables model reason relations several parts image question also experiment replacing a...</td>\n",
              "      <td>sostok dual recurrent attention units for visual question answering  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...</td>\n",
              "      <td>Sequential Short-Text Classification with Recurrent and Convolutional\\n  Neural Networks</td>\n",
              "      <td>recent approaches based artificial neural networks shown promising results short text classification however many short texts occur sequences existing ann based systems leverage preceding short te...</td>\n",
              "      <td>sostok sequential short text classification with recurrent and convolutional neural networks  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a ...</td>\n",
              "      <td>Multiresolution Recurrent Neural Networks: An Application to Dialogue\\n  Response Generation</td>\n",
              "      <td>natural language tokens optimizing joint log likelihood biases model towards modeling high level abstractions finally experiments demonstrate proposed model adept overcoming sparsity natural langu...</td>\n",
              "      <td>sostok multiresolution recurrent neural networks an application to dialogue response generation  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related...</td>\n",
              "      <td>Learning what to share between loosely related tasks</td>\n",
              "      <td>natural language processing hard predict sharing lead improvements particularly tasks loosely related perform experiments three task pairs across seven different domains using data ontonotes achie...</td>\n",
              "      <td>sostok learning what to share between loosely related tasks  eostok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of convers...</td>\n",
              "      <td>A Deep Reinforcement Learning Chatbot</td>\n",
              "      <td>applying reinforcement learning crowdsourced data real world user interactions system trained select appropriate response models ensemble system evaluated testing real world users performed signif...</td>\n",
              "      <td>sostok deep reinforcement learning chatbot  eostok</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                  Abstract  ...                                                                                                  summary\n",
              "0  We propose an architecture for VQA which utilizes recurrent layers to\\ngenerate visual and textual attention. The memory characteristic of the\\nproposed recurrent attention units offers a rich joi...  ...                              sostok dual recurrent attention units for visual question answering  eostok\n",
              "1  Recent approaches based on artificial neural networks (ANNs) have shown\\npromising results for short-text classification. However, many short texts\\noccur in sequences (e.g., sentences in a docume...  ...     sostok sequential short text classification with recurrent and convolutional neural networks  eostok\n",
              "2  We introduce the multiresolution recurrent neural network, which extends the\\nsequence-to-sequence framework to model natural language generation as two\\nparallel discrete stochastic processes: a ...  ...  sostok multiresolution recurrent neural networks an application to dialogue response generation  eostok\n",
              "3  Multi-task learning is motivated by the observation that humans bring to bear\\nwhat they know about related problems when solving new ones. Similarly, deep\\nneural networks can profit from related...  ...                                      sostok learning what to share between loosely related tasks  eostok\n",
              "4  We present MILABOT: a deep reinforcement learning chatbot developed by the\\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\\ncompetition. MILABOT is capable of convers...  ...                                                       sostok deep reinforcement learning chatbot  eostok\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzB20Xu0qUOv",
        "colab_type": "text"
      },
      "source": [
        "Split the data into train and validation set in 90/10 ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWpnRjU-XcCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = int(len(df)*0.1)\n",
        "x_val_org_abs = []\n",
        "x_val_org_title = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "x_tr = []\n",
        "y_tr = []\n",
        "val_samples = random.sample(range(len(df)), l)\n",
        "for i in range(len(df)):\n",
        "  if(i in val_samples):\n",
        "    x_val_org_abs.append(df['Abstract'][i])\n",
        "    x_val_org_title.append(df['Title'][i])\n",
        "    x_val.append(df['text'][i])\n",
        "    y_val.append(df['summary'][i])\n",
        "  else:\n",
        "    x_tr.append(df['text'][i])\n",
        "    y_tr.append(df['summary'][i])\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)\n",
        "x_tr = np.array(x_tr)\n",
        "y_tr = np.array(y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo68ShraCoh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=1,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmXXJNFxRLZk",
        "colab_type": "code",
        "outputId": "4f1bc1cf-ca39-4600-8029-2ab1ef475bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_tr), len(y_tr), len(x_val), len(y_val)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52830, 52830, 5870, 5870)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypTaeQSQqhj2",
        "colab_type": "text"
      },
      "source": [
        "# Tokenizer\n",
        "Converting words to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fksSzdxhRxlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer() \n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzepL1vsrD4T",
        "colab_type": "text"
      },
      "source": [
        "## Rarewords and its Coverage\n",
        "Let us look at the proportion rare words and its total coverage in the entire summary\n",
        "<br>\n",
        "Here, I am defining the threshold to be 6 which means word whose count is below 6 is considered as a rare word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkO4zqTaSIkG",
        "colab_type": "code",
        "outputId": "2df7b58a-c0c3-42fb-c9ae-e8007983d36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 62.458870609159625\n",
            "Total Coverage of rare words: 1.3320290679721463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDkZS1EzDwGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7tp5HC4EDKK",
        "colab_type": "code",
        "outputId": "dc9178f8-1304-45b6-af00-25bc04c676f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx-XukrkSgh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()   \n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu10G-_PSXzg",
        "colab_type": "code",
        "outputId": "4ba5aec8-0989-40d1-dfea-0e034476c243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "    \n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 76.36615811373093\n",
            "Total Coverage of rare words: 4.80375884533503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXLpEDiEFHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPWvrXfEEQsi",
        "colab_type": "code",
        "outputId": "0052ac3f-2ea0-4ddf-dffa-b3ee17899dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_voc"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYTmFhV4S2bw",
        "colab_type": "code",
        "outputId": "5d1ce393-fcf3-421f-c1a3-6b41c1c3ab5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52830, 52830)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od9EZ8IxrbY4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Here, I am deleting the rows that contain only START and END tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkUm06rhS3xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwXSXWCzS8ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU4EWrlfrgQ4",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "This is an encoder decoder model.\n",
        "<br>\n",
        "Encoder has 1 embedding layer and 3 lstm layers\n",
        "decoder has 1 embedding, 1 lstm, 1 attention, 1 concatenation and 1 dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUlu9wdhESEA",
        "colab_type": "code",
        "outputId": "1d20c688-f924-40d0-e6cb-e9efbb38ba68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "from keras import backend as K \n",
        "import tensorflow as tf\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "latent_dim = 500\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 200, 200)     5066000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 200, 500), ( 1402000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 200, 500), ( 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    1022600     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 200, 500), ( 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  1402000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 5113)   5118113     concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 18,515,213\n",
            "Trainable params: 18,515,213\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGW30pT9EexX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0OGAa2Lrm47",
        "colab_type": "text"
      },
      "source": [
        "Use EarlyStopping to stop when validation loss starts to increase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f0SCXfiFkfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QPqc3VTFn-n",
        "colab_type": "code",
        "outputId": "73ac8e45-2e52-490f-9d0f-ca7347ca30ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52804 samples, validate on 5867 samples\n",
            "Epoch 1/50\n",
            "52804/52804 [==============================] - 579s 11ms/sample - loss: 3.9093 - acc: 0.4380 - val_loss: 3.5373 - val_acc: 0.4692\n",
            "Epoch 2/50\n",
            "52804/52804 [==============================] - 580s 11ms/sample - loss: 3.4495 - acc: 0.4738 - val_loss: 3.2738 - val_acc: 0.4918\n",
            "Epoch 3/50\n",
            "52804/52804 [==============================] - 577s 11ms/sample - loss: 3.2178 - acc: 0.4941 - val_loss: 3.1084 - val_acc: 0.5075\n",
            "Epoch 4/50\n",
            "52804/52804 [==============================] - 569s 11ms/sample - loss: 3.0531 - acc: 0.5088 - val_loss: 2.9940 - val_acc: 0.5208\n",
            "Epoch 5/50\n",
            "52804/52804 [==============================] - 568s 11ms/sample - loss: 2.9307 - acc: 0.5193 - val_loss: 2.9198 - val_acc: 0.5267\n",
            "Epoch 6/50\n",
            "52804/52804 [==============================] - 570s 11ms/sample - loss: 2.8309 - acc: 0.5284 - val_loss: 2.8782 - val_acc: 0.5310\n",
            "Epoch 7/50\n",
            "52804/52804 [==============================] - 569s 11ms/sample - loss: 2.7476 - acc: 0.5353 - val_loss: 2.8402 - val_acc: 0.5347\n",
            "Epoch 8/50\n",
            "52804/52804 [==============================] - 567s 11ms/sample - loss: 2.6745 - acc: 0.5418 - val_loss: 2.8036 - val_acc: 0.5384\n",
            "Epoch 9/50\n",
            "52804/52804 [==============================] - 567s 11ms/sample - loss: 2.6116 - acc: 0.5480 - val_loss: 2.7828 - val_acc: 0.5411\n",
            "Epoch 10/50\n",
            "52804/52804 [==============================] - 571s 11ms/sample - loss: 2.5513 - acc: 0.5537 - val_loss: 2.7624 - val_acc: 0.5443\n",
            "Epoch 11/50\n",
            "52804/52804 [==============================] - 578s 11ms/sample - loss: 2.4972 - acc: 0.5591 - val_loss: 2.7508 - val_acc: 0.5447\n",
            "Epoch 12/50\n",
            "52804/52804 [==============================] - 573s 11ms/sample - loss: 2.4477 - acc: 0.5643 - val_loss: 2.7450 - val_acc: 0.5467\n",
            "Epoch 13/50\n",
            "52804/52804 [==============================] - 573s 11ms/sample - loss: 2.4021 - acc: 0.5681 - val_loss: 2.7434 - val_acc: 0.5479\n",
            "Epoch 14/50\n",
            "52804/52804 [==============================] - 571s 11ms/sample - loss: 2.3580 - acc: 0.5731 - val_loss: 2.7267 - val_acc: 0.5498\n",
            "Epoch 15/50\n",
            "52804/52804 [==============================] - 570s 11ms/sample - loss: 2.3188 - acc: 0.5773 - val_loss: 2.7264 - val_acc: 0.5490\n",
            "Epoch 16/50\n",
            "52804/52804 [==============================] - 568s 11ms/sample - loss: 2.2821 - acc: 0.5808 - val_loss: 2.7321 - val_acc: 0.5513\n",
            "Epoch 17/50\n",
            "52804/52804 [==============================] - 569s 11ms/sample - loss: 2.2441 - acc: 0.5849 - val_loss: 2.7192 - val_acc: 0.5514\n",
            "Epoch 18/50\n",
            "52804/52804 [==============================] - 566s 11ms/sample - loss: 2.2093 - acc: 0.5887 - val_loss: 2.7278 - val_acc: 0.5514\n",
            "Epoch 19/50\n",
            "52804/52804 [==============================] - 565s 11ms/sample - loss: 2.1800 - acc: 0.5921 - val_loss: 2.7211 - val_acc: 0.5523\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TVsgOFnFtev",
        "colab_type": "code",
        "outputId": "c73e2665-cd80-4338-b520-b7174d987ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0XAD6Wr3UX",
        "colab_type": "text"
      },
      "source": [
        "define dictionaries to convert integers to their corrosponding words for text and titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsHTiYSeF01J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX804Nh7sqAq",
        "colab_type": "text"
      },
      "source": [
        "# Inference\n",
        "Setting up inference for the encoder and decoder. It is used for prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcrjkEk5GDk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs92XkqHszzk",
        "colab_type": "text"
      },
      "source": [
        "Function for implementing the Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDVQrgImGPEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "      \n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEFGMwM8tBZx",
        "colab_type": "text"
      },
      "source": [
        "Let us define the functions to convert an integer sequence to a word sequence for title as well as the abstract:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG-Pepi7GT89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9bC1ZV1tGJr",
        "colab_type": "text"
      },
      "source": [
        "Predict 100 titles from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSF96xvpG5KV",
        "colab_type": "code",
        "outputId": "618eb1c8-b431-4f82-bdad-a09f6a4bdafc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Abstract:\",x_val_org_abs[i])\n",
        "    print(\"Extracted Text: \", seq2text(x_val[i]))\n",
        "    print(\"Original title:\",x_val_org_title[i])\n",
        "    print(\"Cleaned summary:\",seq2summary(y_val[i]))\n",
        "    print(\"Predicted title:\",decode_sequence(x_val[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Abstract: We introduce the multiresolution recurrent neural network, which extends the\n",
            "sequence-to-sequence framework to model natural language generation as two\n",
            "parallel discrete stochastic processes: a sequence of high-level coarse tokens,\n",
            "and a sequence of natural language tokens. There are many ways to estimate or\n",
            "learn the high-level coarse tokens, but we argue that a simple extraction\n",
            "procedure is sufficient to capture a wealth of high-level discourse semantics.\n",
            "Such procedure allows training the multiresolution recurrent neural network by\n",
            "maximizing the exact joint log-likelihood over both sequences. In contrast to\n",
            "the standard log- likelihood objective w.r.t. natural language tokens (word\n",
            "perplexity), optimizing the joint log-likelihood biases the model towards\n",
            "modeling high-level abstractions. We apply the proposed model to the task of\n",
            "dialogue response generation in two challenging domains: the Ubuntu technical\n",
            "support domain, and Twitter conversations. On Ubuntu, the model outperforms\n",
            "competing approaches by a substantial margin, achieving state-of-the-art\n",
            "results according to both automatic evaluation metrics and a human evaluation\n",
            "study. On Twitter, the model appears to generate more relevant and on-topic\n",
            "responses according to automatic evaluation metrics. Finally, our experiments\n",
            "demonstrate that the proposed model is more adept at overcoming the sparsity of\n",
            "natural language and is better able to capture long-term structure.\n",
            "Extracted Text:  natural language tokens optimizing joint log likelihood biases model towards modeling high level abstractions finally experiments demonstrate proposed model adept overcoming sparsity natural language better able capture long term structure many ways estimate learn high level coarse tokens argue simple extraction procedure sufficient capture wealth high level discourse semantics ubuntu model outperforms competing approaches substantial margin achieving state art results according automatic evaluation metrics human evaluation study apply proposed model task dialogue response generation two challenging domains ubuntu technical support domain twitter conversations introduce multiresolution recurrent neural network extends sequence sequence framework model natural language generation two parallel discrete stochastic processes sequence high level coarse tokens sequence natural language tokens twitter model appears generate relevant topic responses according automatic evaluation metrics procedure allows training multiresolution recurrent neural network maximizing exact joint log likelihood sequences contrast standard log likelihood objective \n",
            "Original title: Multiresolution Recurrent Neural Networks: An Application to Dialogue\n",
            "  Response Generation\n",
            "Cleaned summary: multiresolution recurrent neural networks an application to dialogue response generation \n",
            "Predicted title:  learning to generate spoken language models with recurrent neural networks\n",
            "\n",
            "\n",
            "Abstract: We present MILABOT: a deep reinforcement learning chatbot developed by the\n",
            "Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\n",
            "competition. MILABOT is capable of conversing with humans on popular small talk\n",
            "topics through both speech and text. The system consists of an ensemble of\n",
            "natural language generation and retrieval models, including neural network and\n",
            "template-based models. By applying reinforcement learning to crowdsourced data\n",
            "and real-world user interactions, the system has been trained to select an\n",
            "appropriate response from the models in its ensemble. The system has been\n",
            "evaluated through A/B testing with real-world users, where it performed\n",
            "significantly better than other systems. The results highlight the potential of\n",
            "coupling ensemble systems with deep reinforcement learning as a fruitful path\n",
            "for developing real-world, open-domain conversational agents.\n",
            "Extracted Text:  applying reinforcement learning crowdsourced data real world user interactions system trained select appropriate response models ensemble results highlight potential coupling ensemble systems deep reinforcement learning fruitful path developing real world open domain conversational agents system evaluated testing real world users performed significantly better systems system consists ensemble natural language generation retrieval models including neural network template based models present deep reinforcement learning chatbot developed institute learning algorithms amazon alexa prize competition capable conversing humans popular small talk topics speech text \n",
            "Original title: A Deep Reinforcement Learning Chatbot (Short Version)\n",
            "Cleaned summary: deep reinforcement learning chatbot short version \n",
            "Predicted title:  deep reinforcement learning for automated text generation\n",
            "\n",
            "\n",
            "Abstract: In this paper, we address the task of Optical Character Recognition(OCR) for\n",
            "the Telugu script. We present an end-to-end framework that segments the text\n",
            "image, classifies the characters and extracts lines using a language model. The\n",
            "segmentation is based on mathematical morphology. The classification module,\n",
            "which is the most challenging task of the three, is a deep convolutional neural\n",
            "network. The language is modelled as a third degree markov chain at the glyph\n",
            "level. Telugu script is a complex alphasyllabary and the language is\n",
            "agglutinative, making the problem hard. In this paper we apply the latest\n",
            "advances in neural networks to achieve state-of-the-art error rates. We also\n",
            "review convolutional neural networks in great detail and expound the\n",
            "statistical justification behind the many tricks needed to make Deep Learning\n",
            "work.\n",
            "Extracted Text:  present end end framework segments text image classifies characters extracts lines using language model also review convolutional neural networks great detail statistical justification behind many tricks needed make deep learning work paper apply latest advances neural networks achieve state art error rates paper address task optical character recognition telugu script language modelled third degree markov chain glyph level telugu script complex language agglutinative making problem hard classification module challenging task three deep convolutional neural network segmentation based mathematical morphology \n",
            "Original title: Telugu OCR Framework using Deep Learning\n",
            "Cleaned summary: telugu ocr framework using deep learning \n",
            "Predicted title:  handwritten bangla character recognition using deep learning\n",
            "\n",
            "\n",
            "Abstract: The ability of the Generative Adversarial Networks (GANs) framework to learn\n",
            "generative models mapping from simple latent distributions to arbitrarily\n",
            "complex data distributions has been demonstrated empirically, with compelling\n",
            "results showing that the latent space of such generators captures semantic\n",
            "variation in the data distribution. Intuitively, models trained to predict\n",
            "these semantic latent representations given data may serve as useful feature\n",
            "representations for auxiliary problems where semantics are relevant. However,\n",
            "in their existing form, GANs have no means of learning the inverse mapping --\n",
            "projecting data back into the latent space. We propose Bidirectional Generative\n",
            "Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and\n",
            "demonstrate that the resulting learned feature representation is useful for\n",
            "auxiliary supervised discrimination tasks, competitive with contemporary\n",
            "approaches to unsupervised and self-supervised feature learning.\n",
            "Extracted Text:  ability generative adversarial networks framework learn generative models mapping simple latent distributions arbitrarily complex data distributions demonstrated empirically compelling results showing latent space generators captures semantic variation data distribution intuitively models trained predict semantic latent representations given data may serve useful feature representations auxiliary problems semantics relevant propose bidirectional generative adversarial networks means learning inverse mapping demonstrate resulting learned feature representation useful auxiliary supervised discrimination tasks competitive contemporary approaches unsupervised self supervised feature learning however existing form gans means learning inverse mapping projecting data back latent space \n",
            "Original title: Adversarial Feature Learning\n",
            "Cleaned summary: adversarial feature learning \n",
            "Predicted title:  generative adversarial network for semi supervised learning\n",
            "\n",
            "\n",
            "Abstract: We propose a new algorithm for training generative adversarial networks that\n",
            "jointly learns latent codes for both identities (e.g. individual humans) and\n",
            "observations (e.g. specific photographs). By fixing the identity portion of the\n",
            "latent codes, we can generate diverse images of the same subject, and by fixing\n",
            "the observation portion, we can traverse the manifold of subjects while\n",
            "maintaining contingent aspects such as lighting and pose. Our algorithm\n",
            "features a pairwise training scheme in which each sample from the generator\n",
            "consists of two images with a common identity code. Corresponding samples from\n",
            "the real dataset consist of two distinct photographs of the same subject. In\n",
            "order to fool the discriminator, the generator must produce pairs that are\n",
            "photorealistic, distinct, and appear to depict the same individual. We augment\n",
            "both the DCGAN and BEGAN approaches with Siamese discriminators to facilitate\n",
            "pairwise training. Experiments with human judges and an off-the-shelf face\n",
            "verification system demonstrate our algorithm's ability to generate convincing,\n",
            "identity-matched photographs.\n",
            "Extracted Text:  experiments human judges shelf face verification system demonstrate algorithm ability generate convincing identity matched photographs fixing identity portion latent codes generate diverse images subject fixing observation portion traverse manifold subjects maintaining contingent aspects lighting pose algorithm features pairwise training scheme sample generator consists two images common identity code corresponding samples real dataset consist two distinct photographs subject order fool discriminator generator must produce pairs photorealistic distinct appear depict individual propose new algorithm training generative adversarial networks jointly learns latent codes identities individual humans observations augment dcgan began approaches siamese discriminators facilitate pairwise training \n",
            "Original title: Semantically Decomposing the Latent Spaces of Generative Adversarial\n",
            "  Networks\n",
            "Cleaned summary: semantically the latent spaces of generative adversarial networks \n",
            "Predicted title:  generative adversarial network for visual face verification\n",
            "\n",
            "\n",
            "Abstract: Regularization is one of the crucial ingredients of deep learning, yet the\n",
            "term regularization has various definitions, and regularization methods are\n",
            "often studied separately from each other. In our work we present a systematic,\n",
            "unifying taxonomy to categorize existing methods. We distinguish methods that\n",
            "affect data, network architectures, error terms, regularization terms, and\n",
            "optimization procedures. We do not provide all details about the listed\n",
            "methods; instead, we present an overview of how the methods can be sorted into\n",
            "meaningful categories and sub-categories. This helps revealing links and\n",
            "fundamental similarities between them. Finally, we include practical\n",
            "recommendations both for users and for developers of new regularization\n",
            "methods.\n",
            "Extracted Text:  regularization one crucial ingredients deep learning yet term regularization various definitions regularization methods often studied separately provide details listed methods instead present overview methods sorted meaningful categories sub categories distinguish methods affect data network architectures error terms regularization terms optimization procedures finally include practical recommendations users developers new regularization methods work present systematic unifying taxonomy categorize existing methods helps revealing links fundamental similarities \n",
            "Original title: Regularization for Deep Learning: A Taxonomy\n",
            "Cleaned summary: regularization for deep learning taxonomy \n",
            "Predicted title:  the of the data\n",
            "\n",
            "\n",
            "Abstract: Hybrid methods that utilize both content and rating information are commonly\n",
            "used in many recommender systems. However, most of them use either handcrafted\n",
            "features or the bag-of-words representation as a surrogate for the content\n",
            "information but they are neither effective nor natural enough. To address this\n",
            "problem, we develop a collaborative recurrent autoencoder (CRAE) which is a\n",
            "denoising recurrent autoencoder (DRAE) that models the generation of content\n",
            "sequences in the collaborative filtering (CF) setting. The model generalizes\n",
            "recent advances in recurrent deep learning from i.i.d. input to non-i.i.d.\n",
            "(CF-based) input and provides a new denoising scheme along with a novel\n",
            "learnable pooling scheme for the recurrent autoencoder. To do this, we first\n",
            "develop a hierarchical Bayesian model for the DRAE and then generalize it to\n",
            "the CF setting. The synergy between denoising and CF enables CRAE to make\n",
            "accurate recommendations while learning to fill in the blanks in sequences.\n",
            "Experiments on real-world datasets from different domains (CiteULike and\n",
            "Netflix) show that, by jointly modeling the order-aware generation of sequences\n",
            "for the content information and performing CF for the ratings, CRAE is able to\n",
            "significantly outperform the state of the art on both the recommendation task\n",
            "based on ratings and the sequence generation task based on content information.\n",
            "Extracted Text:  experiments real world datasets different domains show jointly modeling order aware generation sequences content information performing ratings able significantly outperform state art recommendation task based ratings sequence generation task based content information address problem develop collaborative recurrent autoencoder denoising recurrent autoencoder models generation content sequences collaborative filtering setting hybrid methods utilize content rating information commonly used many recommender systems however use either handcrafted features bag words representation surrogate content information neither effective natural enough synergy denoising enables make accurate recommendations learning fill sequences input provides new denoising scheme along novel learnable pooling scheme recurrent autoencoder model generalizes recent advances recurrent deep learning first develop hierarchical bayesian model generalize setting input non \n",
            "Original title: Collaborative Recurrent Autoencoder: Recommend while Learning to Fill in\n",
            "  the Blanks\n",
            "Cleaned summary: collaborative recurrent autoencoder while learning to fill in the \n",
            "Predicted title:  recurrent neural network for user aware recommendations\n",
            "\n",
            "\n",
            "Abstract: When encountering novel objects, humans are able to infer a wide range of\n",
            "physical properties such as mass, friction and deformability by interacting\n",
            "with them in a goal driven way. This process of active interaction is in the\n",
            "same spirit as a scientist performing experiments to discover hidden facts.\n",
            "Recent advances in artificial intelligence have yielded machines that can\n",
            "achieve superhuman performance in Go, Atari, natural language processing, and\n",
            "complex control problems; however, it is not clear that these systems can rival\n",
            "the scientific intuition of even a young child. In this work we introduce a\n",
            "basic set of tasks that require agents to estimate properties such as mass and\n",
            "cohesion of objects in an interactive simulated environment where they can\n",
            "manipulate the objects and observe the consequences. We found that state of art\n",
            "deep reinforcement learning methods can learn to perform the experiments\n",
            "necessary to discover such hidden properties. By systematically manipulating\n",
            "the problem difficulty and the cost incurred by the agent for performing\n",
            "experiments, we found that agents learn different strategies that balance the\n",
            "cost of gathering information against the cost of making mistakes in different\n",
            "situations.\n",
            "Extracted Text:  found state art deep reinforcement learning methods learn perform experiments necessary discover hidden properties recent advances artificial intelligence yielded machines achieve superhuman performance atari natural language processing complex control problems however clear systems rival scientific intuition even young child work introduce basic set tasks require agents estimate properties mass cohesion objects interactive simulated environment manipulate objects observe consequences systematically manipulating problem difficulty cost incurred agent performing experiments found agents learn different strategies balance cost gathering information cost making mistakes different situations encountering novel objects humans able infer wide range physical properties mass friction interacting goal driven way process active interaction spirit scientist performing experiments discover hidden facts \n",
            "Original title: Learning to Perform Physics Experiments via Deep Reinforcement Learning\n",
            "Cleaned summary: learning to perform physics experiments via deep reinforcement learning \n",
            "Predicted title:  towards understanding the of the deep learning framework\n",
            "\n",
            "\n",
            "Abstract: Hypothesis testing is an important cognitive process that supports human\n",
            "reasoning. In this paper, we introduce a computational hypothesis testing\n",
            "approach based on memory augmented neural networks. Our approach involves a\n",
            "hypothesis testing loop that reconsiders and progressively refines a previously\n",
            "formed hypothesis in order to generate new hypotheses to test. We apply the\n",
            "proposed approach to language comprehension task by using Neural Semantic\n",
            "Encoders (NSE). Our NSE models achieve the state-of-the-art results showing an\n",
            "absolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\n",
            "single and ensemble systems on standard machine comprehension benchmarks such\n",
            "as the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.\n",
            "Extracted Text:  paper introduce computational hypothesis testing approach based memory augmented neural networks hypothesis testing important cognitive process supports human reasoning approach involves hypothesis testing loop reconsiders progressively refines previously formed hypothesis order generate new hypotheses test apply proposed approach language comprehension task using neural semantic encoders nse models achieve state art results showing absolute improvement accuracy previous results obtained single ensemble systems standard machine comprehension benchmarks children book test news article datasets \n",
            "Original title: Reasoning with Memory Augmented Neural Networks for Language\n",
            "  Comprehension\n",
            "Cleaned summary: reasoning with memory augmented neural networks for language comprehension \n",
            "Predicted title:  neural semantic role labeling with neural machine\n",
            "\n",
            "\n",
            "Abstract: Objective: We investigate whether deep learning techniques for natural\n",
            "language processing (NLP) can be used efficiently for patient phenotyping.\n",
            "Patient phenotyping is a classification task for determining whether a patient\n",
            "has a medical condition, and is a crucial part of secondary analysis of\n",
            "healthcare data. We assess the performance of deep learning algorithms and\n",
            "compare them with classical NLP approaches.\n",
            "  Materials and Methods: We compare convolutional neural networks (CNNs),\n",
            "n-gram models, and approaches based on cTAKES that extract pre-defined medical\n",
            "concepts from clinical notes and use them to predict patient phenotypes. The\n",
            "performance is tested on 10 different phenotyping tasks using 1,610 discharge\n",
            "summaries extracted from the MIMIC-III database.\n",
            "  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\n",
            "average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\n",
            "model having an F1-score up to 37 points higher than alternative approaches. We\n",
            "additionally assess the interpretability of our model by presenting a method\n",
            "that extracts the most salient phrases for a particular prediction.\n",
            "  Conclusion: We show that NLP methods based on deep learning improve the\n",
            "performance of patient phenotyping. Our CNN-based algorithm automatically\n",
            "learns the phrases associated with each patient phenotype. As such, it reduces\n",
            "the annotation complexity for clinical domain experts, who are normally\n",
            "required to develop task-specific annotation rules and identify relevant\n",
            "phrases. Our method performs well in terms of both performance and\n",
            "interpretability, which indicates that deep learning is an effective approach\n",
            "to patient phenotyping based on clinicians' notes.\n",
            "Extracted Text:  method performs well terms performance interpretability indicates deep learning effective approach patient phenotyping based clinicians notes conclusion show nlp methods based deep learning improve performance patient phenotyping materials methods compare convolutional neural networks gram models approaches based ctakes extract pre defined medical concepts clinical notes use predict patient phenotypes objective investigate whether deep learning techniques natural language processing used efficiently patient phenotyping reduces annotation complexity clinical domain experts normally required develop task specific annotation rules identify relevant phrases performance tested different phenotyping tasks using discharge summaries extracted mimic iii database additionally assess interpretability model presenting method extracts salient phrases particular prediction assess performance deep learning algorithms compare classical nlp approaches patient phenotyping classification task determining whether patient medical condition crucial part secondary analysis healthcare data cnn based algorithm automatically learns phrases associated patient phenotype \n",
            "Original title: Comparing Rule-Based and Deep Learning Models for Patient Phenotyping\n",
            "Cleaned summary: comparing rule based and deep learning models for patient phenotyping \n",
            "Predicted title:  deep learning for medical image summarization\n",
            "\n",
            "\n",
            "Abstract: We address an important problem in sequence-to-sequence (Seq2Seq) learning\n",
            "referred to as copying, in which certain segments in the input sequence are\n",
            "selectively replicated in the output sequence. A similar phenomenon is\n",
            "observable in human language communication. For example, humans tend to repeat\n",
            "entity names or even long phrases in conversation. The challenge with regard to\n",
            "copying in Seq2Seq is that new machinery is needed to decide when to perform\n",
            "the operation. In this paper, we incorporate copying into neural network-based\n",
            "Seq2Seq learning and propose a new model called CopyNet with encoder-decoder\n",
            "structure. CopyNet can nicely integrate the regular way of word generation in\n",
            "the decoder with the new copying mechanism which can choose sub-sequences in\n",
            "the input sequence and put them at proper places in the output sequence. Our\n",
            "empirical study on both synthetic data sets and real world data sets\n",
            "demonstrates the efficacy of CopyNet. For example, CopyNet can outperform\n",
            "regular RNN-based model with remarkable margins on text summarization tasks.\n",
            "Extracted Text:  nicely integrate regular way word generation decoder new copying mechanism choose sub sequences input sequence put proper places output sequence address important problem sequence sequence learning referred copying certain segments input sequence selectively replicated output sequence example outperform regular rnn based model remarkable margins text summarization tasks empirical study synthetic data sets real world data sets demonstrates efficacy example humans tend repeat entity names even long phrases conversation paper incorporate copying neural network based seq seq learning propose new model called encoder decoder structure similar phenomenon observable human language communication challenge regard copying seq seq new machinery needed decide perform operation \n",
            "Original title: Incorporating Copying Mechanism in Sequence-to-Sequence Learning\n",
            "Cleaned summary: incorporating mechanism in sequence to sequence learning \n",
            "Predicted title:  neural network based model for sentence compression\n",
            "\n",
            "\n",
            "Abstract: Long Short-Term Memory (LSTM) is a recurrent neural network (RNN)\n",
            "architecture that has been designed to address the vanishing and exploding\n",
            "gradient problems of conventional RNNs. Unlike feedforward neural networks,\n",
            "RNNs have cyclic connections making them powerful for modeling sequences. They\n",
            "have been successfully used for sequence labeling and sequence prediction\n",
            "tasks, such as handwriting recognition, language modeling, phonetic labeling of\n",
            "acoustic frames. However, in contrast to the deep neural networks, the use of\n",
            "RNNs in speech recognition has been limited to phone recognition in small scale\n",
            "tasks. In this paper, we present novel LSTM based RNN architectures which make\n",
            "more effective use of model parameters to train acoustic models for large\n",
            "vocabulary speech recognition. We train and compare LSTM, RNN and DNN models at\n",
            "various numbers of parameters and configurations. We show that LSTM models\n",
            "converge quickly and give state of the art speech recognition performance for\n",
            "relatively small sized models.\n",
            "Extracted Text:  paper present novel lstm based rnn architectures make effective use model parameters train acoustic models large vocabulary speech recognition however contrast deep neural networks use rnns speech recognition limited phone recognition small scale tasks long short term memory recurrent neural network architecture designed address vanishing exploding gradient problems conventional rnns show lstm models converge quickly give state art speech recognition performance relatively small sized models successfully used sequence labeling sequence prediction tasks handwriting recognition language modeling phonetic labeling acoustic frames unlike feedforward neural networks rnns cyclic connections making powerful modeling sequences train compare lstm rnn dnn models various numbers parameters configurations \n",
            "Original title: Long Short-Term Memory Based Recurrent Neural Network Architectures for\n",
            "  Large Vocabulary Speech Recognition\n",
            "Cleaned summary: long short term memory based recurrent neural network architectures for large vocabulary speech recognition \n",
            "Predicted title:  speech recognition with recurrent neural networks\n",
            "\n",
            "\n",
            "Abstract: End-to-end training of automated speech recognition (ASR) systems requires\n",
            "massive data and compute resources. We explore transfer learning based on model\n",
            "adaptation as an approach for training ASR models under constrained GPU memory,\n",
            "throughput and training data. We conduct several systematic experiments\n",
            "adapting a Wav2Letter convolutional neural network originally trained for\n",
            "English ASR to the German language. We show that this technique allows faster\n",
            "training on consumer-grade resources while requiring less training data in\n",
            "order to achieve the same accuracy, thereby lowering the cost of training ASR\n",
            "models in other languages. Model introspection revealed that small adaptations\n",
            "to the network's weights were sufficient for good performance, especially for\n",
            "inner layers.\n",
            "Extracted Text:  show technique allows faster training consumer grade resources requiring less training data order achieve accuracy thereby lowering cost training asr models languages explore transfer learning based model adaptation approach training asr models constrained gpu memory throughput training data end end training automated speech recognition systems requires massive data compute resources model introspection revealed small adaptations network weights sufficient good performance especially inner layers conduct several systematic experiments adapting wav letter convolutional neural network originally trained english asr german language \n",
            "Original title: Transfer Learning for Speech Recognition on a Budget\n",
            "Cleaned summary: transfer learning for speech recognition on budget \n",
            "Predicted title:  learning to represent speech for speech recognition\n",
            "\n",
            "\n",
            "Abstract: Unsupervised learning of probabilistic models is a central yet challenging\n",
            "problem in machine learning. Specifically, designing models with tractable\n",
            "learning, sampling, inference and evaluation is crucial in solving this task.\n",
            "We extend the space of such models using real-valued non-volume preserving\n",
            "(real NVP) transformations, a set of powerful invertible and learnable\n",
            "transformations, resulting in an unsupervised learning algorithm with exact\n",
            "log-likelihood computation, exact sampling, exact inference of latent\n",
            "variables, and an interpretable latent space. We demonstrate its ability to\n",
            "model natural images on four datasets through sampling, log-likelihood\n",
            "evaluation and latent variable manipulations.\n",
            "Extracted Text:  extend space models using real valued non volume preserving transformations set powerful invertible learnable transformations resulting unsupervised learning algorithm exact log likelihood computation exact sampling exact inference latent variables interpretable latent space demonstrate ability model natural images four datasets sampling log likelihood evaluation latent variable manipulations unsupervised learning probabilistic models central yet challenging problem machine learning specifically designing models tractable learning sampling inference evaluation crucial solving task \n",
            "Original title: Density estimation using Real NVP\n",
            "Cleaned summary: density estimation using real \n",
            "Predicted title:  learning latent variable models with gaussian processes\n",
            "\n",
            "\n",
            "Abstract: Deep reinforcement learning (deep RL) has been successful in learning\n",
            "sophisticated behaviors automatically; however, the learning process requires a\n",
            "huge number of trials. In contrast, animals can learn new tasks in just a few\n",
            "trials, benefiting from their prior knowledge about the world. This paper seeks\n",
            "to bridge this gap. Rather than designing a \"fast\" reinforcement learning\n",
            "algorithm, we propose to represent it as a recurrent neural network (RNN) and\n",
            "learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in\n",
            "the weights of the RNN, which are learned slowly through a general-purpose\n",
            "(\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm\n",
            "would receive, including observations, actions, rewards, and termination flags;\n",
            "and it retains its state across episodes in a given Markov Decision Process\n",
            "(MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on\n",
            "the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both\n",
            "small-scale and large-scale problems. On the small-scale side, we train it to\n",
            "solve randomly generated multi-arm bandit problems and finite MDPs. After\n",
            "RL$^2$ is trained, its performance on new MDPs is close to human-designed\n",
            "algorithms with optimality guarantees. On the large-scale side, we test RL$^2$\n",
            "on a vision-based navigation task and show that it scales up to\n",
            "high-dimensional problems.\n",
            "Extracted Text:  deep reinforcement learning successful learning sophisticated behaviors automatically however learning process requires huge number trials large scale side test vision based navigation task show scales high dimensional problems rnn receives information typical algorithm would receive including observations actions rewards termination retains state across episodes given markov decision process rather designing fast reinforcement learning algorithm propose represent recurrent neural network learn data trained performance new mdps close human designed algorithms optimality guarantees small scale side train solve randomly generated multi arm bandit problems finite mdps contrast animals learn new tasks trials benefiting prior knowledge world evaluate experimentally small scale large scale problems proposed method algorithm encoded weights rnn learned slowly general purpose algorithm activations rnn store state fast algorithm current mdp \n",
            "Original title: RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning\n",
            "Cleaned summary: rl fast reinforcement learning via slow reinforcement learning \n",
            "Predicted title:  learning to with recurrent neural networks\n",
            "\n",
            "\n",
            "Abstract: Conventional wisdom holds that model-based planning is a powerful approach to\n",
            "sequential decision-making. It is often very challenging in practice, however,\n",
            "because while a model can be used to evaluate a plan, it does not prescribe how\n",
            "to construct a plan. Here we introduce the \"Imagination-based Planner\", the\n",
            "first model-based, sequential decision-making agent that can learn to\n",
            "construct, evaluate, and execute plans. Before any action, it can perform a\n",
            "variable number of imagination steps, which involve proposing an imagined\n",
            "action and evaluating it with its model-based imagination. All imagined actions\n",
            "and outcomes are aggregated, iteratively, into a \"plan context\" which\n",
            "conditions future real and imagined actions. The agent can even decide how to\n",
            "imagine: testing out alternative imagined actions, chaining sequences of\n",
            "actions together, or building a more complex \"imagination tree\" by navigating\n",
            "flexibly among the previously imagined states using a learned policy. And our\n",
            "agent can learn to plan economically, jointly optimizing for external rewards\n",
            "and computational costs associated with using its imagination. We show that our\n",
            "architecture can learn to solve a challenging continuous control problem, and\n",
            "also learn elaborate planning strategies in a discrete maze-solving task. Our\n",
            "work opens a new direction toward learning the components of a model-based\n",
            "planning system and how to use them.\n",
            "Extracted Text:  action perform variable number imagination steps involve proposing imagined action evaluating model based imagination agent even decide imagine testing alternative imagined actions chaining sequences actions together building complex imagination tree navigating flexibly among previously imagined states using learned policy introduce imagination based planner first model based sequential decision making agent learn construct evaluate execute plans often challenging practice however model used evaluate plan prescribe construct plan work opens new direction toward learning components model based planning system use show architecture learn solve challenging continuous control problem also learn elaborate planning strategies discrete maze solving task conventional wisdom holds model based planning powerful approach sequential decision making agent learn plan economically jointly optimizing external rewards computational costs associated using imagination imagined actions outcomes aggregated iteratively plan context conditions future real imagined actions \n",
            "Original title: Learning model-based planning from scratch\n",
            "Cleaned summary: learning model based planning from scratch \n",
            "Predicted title:  learning to plan state\n",
            "\n",
            "\n",
            "Abstract: Despite their ability to memorize large datasets, deep neural networks often\n",
            "achieve good generalization performance. However, the differences between the\n",
            "learned solutions of networks which generalize and those which do not remain\n",
            "unclear. Additionally, the tuning properties of single directions (defined as\n",
            "the activation of a single unit or some linear combination of units in response\n",
            "to some input) have been highlighted, but their importance has not been\n",
            "evaluated. Here, we connect these lines of inquiry to demonstrate that a\n",
            "network's reliance on single directions is a good predictor of its\n",
            "generalization performance, across networks trained on datasets with different\n",
            "fractions of corrupted labels, across ensembles of networks trained on datasets\n",
            "with unmodified labels, across different hyperparameters, and over the course\n",
            "of training. While dropout only regularizes this quantity up to a point, batch\n",
            "normalization implicitly discourages single direction reliance, in part by\n",
            "decreasing the class selectivity of individual units. Finally, we find that\n",
            "class selectivity is a poor predictor of task importance, suggesting not only\n",
            "that networks which generalize well minimize their dependence on individual\n",
            "units by reducing their selectivity, but also that individually selective units\n",
            "may not be necessary for strong network performance.\n",
            "Extracted Text:  finally find class selectivity poor predictor task importance suggesting networks generalize well minimize dependence individual units reducing selectivity also individually selective units may necessary strong network performance despite ability memorize large datasets deep neural networks often achieve good generalization performance connect lines inquiry demonstrate network reliance single directions good predictor generalization performance across networks trained datasets different fractions corrupted labels across ensembles networks trained datasets unmodified labels across different hyperparameters course training additionally tuning properties single directions highlighted importance evaluated however differences learned solutions networks generalize remain unclear dropout regularizes quantity point batch normalization implicitly discourages single direction reliance part decreasing class selectivity individual units \n",
            "Original title: On the importance of single directions for generalization\n",
            "Cleaned summary: on the importance of single directions for generalization \n",
            "Predicted title:  the of neural networks\n",
            "\n",
            "\n",
            "Abstract: An ever increasing number of computer vision and image/video processing\n",
            "challenges are being approached using deep convolutional neural networks,\n",
            "obtaining state-of-the-art results in object recognition and detection,\n",
            "semantic segmentation, action recognition, optical flow and superresolution.\n",
            "Hardware acceleration of these algorithms is essential to adopt these\n",
            "improvements in embedded and mobile computer vision systems. We present a new\n",
            "architecture, design and implementation as well as the first reported silicon\n",
            "measurements of such an accelerator, outperforming previous work in terms of\n",
            "power-, area- and I/O-efficiency. The manufactured device provides up to 196\n",
            "GOp/s on 3.09 mm^2 of silicon in UMC 65nm technology and can achieve a power\n",
            "efficiency of 803 GOp/s/W. The massively reduced bandwidth requirements make it\n",
            "the first architecture scalable to TOp/s performance.\n",
            "Extracted Text:  present new architecture design implementation well first reported silicon measurements accelerator outperforming previous work terms power area efficiency ever increasing number computer vision image video processing challenges approached using deep convolutional neural networks obtaining state art results object recognition detection semantic segmentation action recognition optical flow superresolution massively reduced bandwidth requirements make first architecture scalable top performance hardware acceleration algorithms essential adopt improvements embedded mobile computer vision systems manufactured device provides gop silicon technology achieve power efficiency gop \n",
            "Original title: Origami: A 803 GOp/s/W Convolutional Network Accelerator\n",
            "Cleaned summary: convolutional network accelerator \n",
            "Predicted title:  fast and accurate video object recognition using deep convolutional neural network\n",
            "\n",
            "\n",
            "Abstract: We derive a relationship between network representation in energy-efficient\n",
            "neuromorphic architectures and block Toplitz convolutional matrices. Inspired\n",
            "by this connection, we develop deep convolutional networks using a family of\n",
            "structured convolutional matrices and achieve state-of-the-art trade-off\n",
            "between energy efficiency and classification accuracy for well-known image\n",
            "recognition tasks. We also put forward a novel method to train binary\n",
            "convolutional networks by utilising an existing connection between\n",
            "noisy-rectified linear units and binary activations.\n",
            "Extracted Text:  derive relationship network representation energy efficient neuromorphic architectures block convolutional matrices also put forward novel method train binary convolutional networks utilising existing connection noisy rectified linear units binary activations inspired connection develop deep convolutional networks using family structured convolutional matrices achieve state art trade energy efficiency classification accuracy well known image recognition tasks \n",
            "Original title: Structured Convolution Matrices for Energy-efficient Deep learning\n",
            "Cleaned summary: structured convolution matrices for energy efficient deep learning \n",
            "Predicted title:  convolutional networks for image classification\n",
            "\n",
            "\n",
            "Abstract: 3D action recognition - analysis of human actions based on 3D skeleton data -\n",
            "becomes popular recently due to its succinctness, robustness, and\n",
            "view-invariant representation. Recent attempts on this problem suggested to\n",
            "develop RNN-based learning methods to model the contextual dependency in the\n",
            "temporal domain. In this paper, we extend this idea to spatio-temporal domains\n",
            "to analyze the hidden sources of action-related information within the input\n",
            "data over both domains concurrently. Inspired by the graphical structure of the\n",
            "human skeleton, we further propose a more powerful tree-structure based\n",
            "traversal method. To handle the noise and occlusion in 3D skeleton data, we\n",
            "introduce new gating mechanism within LSTM to learn the reliability of the\n",
            "sequential input data and accordingly adjust its effect on updating the\n",
            "long-term context information stored in the memory cell. Our method achieves\n",
            "state-of-the-art performance on 4 challenging benchmark datasets for 3D human\n",
            "action analysis.\n",
            "Extracted Text:  action recognition analysis human actions based skeleton data becomes popular recently due succinctness robustness view invariant representation recent attempts problem suggested develop rnn based learning methods model contextual dependency temporal domain handle noise occlusion skeleton data introduce new gating mechanism within lstm learn reliability sequential input data accordingly adjust effect updating long term context information stored memory cell paper extend idea spatio temporal domains analyze hidden sources action related information within input data domains concurrently method achieves state art performance challenging benchmark datasets human action analysis inspired graphical structure human skeleton propose powerful tree structure based traversal method \n",
            "Original title: Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\n",
            "Cleaned summary: spatio temporal lstm with trust gates for human action recognition \n",
            "Predicted title:  temporal recurrent neural network for action recognition\n",
            "\n",
            "\n",
            "Abstract: For complex segmentation tasks, fully automatic systems are inherently\n",
            "limited in their achievable accuracy for extracting relevant objects.\n",
            "Especially in cases where only few data sets need to be processed for a highly\n",
            "accurate result, semi-automatic segmentation techniques exhibit a clear benefit\n",
            "for the user. One area of application is medical image processing during an\n",
            "intervention for a single patient. We propose a learning-based cooperative\n",
            "segmentation approach which includes the computing entity as well as the user\n",
            "into the task. Our system builds upon a state-of-the-art fully convolutional\n",
            "artificial neural network (FCN) as well as an active user model for training.\n",
            "During the segmentation process, a user of the trained system can iteratively\n",
            "add additional hints in form of pictorial scribbles as seed points into the FCN\n",
            "system to achieve an interactive and precise segmentation result. The\n",
            "segmentation quality of interactive FCNs is evaluated. Iterative FCN approaches\n",
            "can yield superior results compared to networks without the user input channel\n",
            "component, due to a consistent improvement in segmentation quality after each\n",
            "interaction.\n",
            "Extracted Text:  especially cases data sets need processed highly accurate result semi automatic segmentation techniques exhibit clear benefit user segmentation process user trained system iteratively add additional hints form pictorial scribbles seed points fcn system achieve interactive precise segmentation result iterative fcn approaches yield superior results compared networks without user input channel component due consistent improvement segmentation quality interaction propose learning based cooperative segmentation approach includes computing entity well user task system builds upon state art fully convolutional artificial neural network well active user model training complex segmentation tasks fully automatic systems inherently limited achievable accuracy extracting relevant objects one area application medical image processing intervention single patient segmentation quality interactive fcns evaluated \n",
            "Original title: UI-Net: Interactive Artificial Neural Networks for Iterative Image\n",
            "  Segmentation Based on a User Model\n",
            "Cleaned summary: net interactive artificial neural networks for iterative image segmentation based on user model \n",
            "Predicted title:  automatic liver lesion segmentation using deep learning\n",
            "\n",
            "\n",
            "Abstract: Regularized training of an autoencoder typically results in hidden unit\n",
            "biases that take on large negative values. We show that negative biases are a\n",
            "natural result of using a hidden layer whose responsibility is to both\n",
            "represent the input data and act as a selection mechanism that ensures sparsity\n",
            "of the representation. We then show that negative biases impede the learning of\n",
            "data distributions whose intrinsic dimensionality is high. We also propose a\n",
            "new activation function that decouples the two roles of the hidden layer and\n",
            "that allows us to learn representations on data with very high intrinsic\n",
            "dimensionality, where standard autoencoders typically fail. Since the decoupled\n",
            "activation function acts like an implicit regularizer, the model can be trained\n",
            "by minimizing the reconstruction error of training data, without requiring any\n",
            "additional regularization.\n",
            "Extracted Text:  also propose new activation function decouples two roles hidden layer allows learn representations data high intrinsic dimensionality standard autoencoders typically fail show negative biases natural result using hidden layer whose responsibility represent input data act selection mechanism ensures sparsity representation regularized training autoencoder typically results hidden unit biases take large negative values since decoupled activation function acts like implicit regularizer model trained minimizing reconstruction error training data without requiring additional regularization show negative biases impede learning data distributions whose intrinsic dimensionality high \n",
            "Original title: Zero-bias autoencoders and the benefits of co-adapting features\n",
            "Cleaned summary: zero bias autoencoders and the benefits of co adapting features \n",
            "Predicted title:  learning to rank with\n",
            "\n",
            "\n",
            "Abstract: We propose and systematically evaluate three strategies for training\n",
            "dynamically-routed artificial neural networks: graphs of learned\n",
            "transformations through which different input signals may take different paths.\n",
            "Though some approaches have advantages over others, the resulting networks are\n",
            "often qualitatively similar. We find that, in dynamically-routed networks\n",
            "trained to classify images, layers and branches become specialized to process\n",
            "distinct categories of images. Additionally, given a fixed computational\n",
            "budget, dynamically-routed networks tend to perform better than comparable\n",
            "statically-routed networks.\n",
            "Extracted Text:  propose systematically evaluate three strategies training dynamically routed artificial neural networks graphs learned transformations different input signals may take different paths find dynamically routed networks trained classify images layers branches become specialized process distinct categories images additionally given fixed computational budget dynamically routed networks tend perform better comparable statically routed networks though approaches advantages others resulting networks often qualitatively similar \n",
            "Original title: Deciding How to Decide: Dynamic Routing in Artificial Neural Networks\n",
            "Cleaned summary: how to dynamic routing in artificial neural networks \n",
            "Predicted title:  learning to optimize with neural networks\n",
            "\n",
            "\n",
            "Abstract: Motivated by an important insight from neural science, we propose a new\n",
            "framework for understanding the success of the recently proposed \"maxout\"\n",
            "networks. The framework is based on encoding information on sparse pathways and\n",
            "recognizing the correct pathway at inference time. Elaborating further on this\n",
            "insight, we propose a novel deep network architecture, called \"channel-out\"\n",
            "network, which takes a much better advantage of sparse pathway encoding. In\n",
            "channel-out networks, pathways are not only formed a posteriori, but they are\n",
            "also actively selected according to the inference outputs from the lower\n",
            "layers. From a mathematical perspective, channel-out networks can represent a\n",
            "wider class of piece-wise continuous functions, thereby endowing the network\n",
            "with more expressive power than that of maxout networks. We test our\n",
            "channel-out networks on several well-known image classification benchmarks,\n",
            "setting new state-of-the-art performance on CIFAR-100 and STL-10, which\n",
            "represent some of the \"harder\" image classification benchmarks.\n",
            "Extracted Text:  elaborating insight propose novel deep network architecture called channel network takes much better advantage sparse pathway encoding mathematical perspective channel networks represent wider class piece wise continuous functions thereby endowing network expressive power maxout networks channel networks pathways formed posteriori also actively selected according inference outputs lower layers motivated important insight neural science propose new framework understanding success recently proposed maxout networks test channel networks several well known image classification benchmarks setting new state art performance cifar stl represent harder image classification benchmarks framework based encoding information sparse pathways recognizing correct pathway inference time \n",
            "Original title: From Maxout to Channel-Out: Encoding Information on Sparse Pathways\n",
            "Cleaned summary: from maxout to channel out encoding information on sparse pathways \n",
            "Predicted title:  deep learning for image classification\n",
            "\n",
            "\n",
            "Abstract: Residual networks (ResNets) have recently achieved state-of-the-art on\n",
            "challenging computer vision tasks. We introduce Resnet in Resnet (RiR): a deep\n",
            "dual-stream architecture that generalizes ResNets and standard CNNs and is\n",
            "easily implemented with no computational overhead. RiR consistently improves\n",
            "performance over ResNets, outperforms architectures with similar amounts of\n",
            "augmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100.\n",
            "Extracted Text:  residual networks recently achieved state art challenging computer vision tasks consistently improves performance resnets outperforms architectures similar amounts augmentation cifar establishes new state art cifar introduce resnet resnet deep dual stream architecture generalizes resnets standard cnns easily implemented computational overhead \n",
            "Original title: Resnet in Resnet: Generalizing Residual Architectures\n",
            "Cleaned summary: in generalizing residual architectures \n",
            "Predicted title:  deep residual networks for residual network\n",
            "\n",
            "\n",
            "Abstract: The blind application of machine learning runs the risk of amplifying biases\n",
            "present in data. Such a danger is facing us with word embedding, a popular\n",
            "framework to represent text data as vectors which has been used in many machine\n",
            "learning and natural language processing tasks. We show that even word\n",
            "embeddings trained on Google News articles exhibit female/male gender\n",
            "stereotypes to a disturbing extent. This raises concerns because their\n",
            "widespread use, as we describe, often tends to amplify these biases.\n",
            "Geometrically, gender bias is first shown to be captured by a direction in the\n",
            "word embedding. Second, gender neutral words are shown to be linearly separable\n",
            "from gender definition words in the word embedding. Using these properties, we\n",
            "provide a methodology for modifying an embedding to remove gender stereotypes,\n",
            "such as the association between between the words receptionist and female,\n",
            "while maintaining desired associations such as between the words queen and\n",
            "female. We define metrics to quantify both direct and indirect gender biases in\n",
            "embeddings, and develop algorithms to \"debias\" the embedding. Using\n",
            "crowd-worker evaluation as well as standard benchmarks, we empirically\n",
            "demonstrate that our algorithms significantly reduce gender bias in embeddings\n",
            "while preserving the its useful properties such as the ability to cluster\n",
            "related concepts and to solve analogy tasks. The resulting embeddings can be\n",
            "used in applications without amplifying gender bias.\n",
            "Extracted Text:  using crowd worker evaluation well standard benchmarks empirically demonstrate algorithms significantly reduce gender bias embeddings preserving useful properties ability cluster related concepts solve analogy tasks resulting embeddings used applications without amplifying gender bias danger facing word embedding popular framework represent text data vectors used many machine learning natural language processing tasks using properties provide methodology modifying embedding remove gender stereotypes association words female maintaining desired associations words queen female blind application machine learning runs risk amplifying biases present data geometrically gender bias first shown captured direction word embedding show even word embeddings trained google news articles exhibit female male gender stereotypes disturbing extent second gender neutral words shown linearly separable gender definition words word embedding raises concerns widespread use describe often tends amplify biases define metrics quantify direct indirect gender biases embeddings develop algorithms embedding \n",
            "Original title: Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word\n",
            "  Embeddings\n",
            "Cleaned summary: man is to computer as is to word embeddings \n",
            "Predicted title:  word embeddings for social media\n",
            "\n",
            "\n",
            "Abstract: Chemical databases store information in text representations, and the SMILES\n",
            "format is a universal standard used in many cheminformatics software. Encoded\n",
            "in each SMILES string is structural information that can be used to predict\n",
            "complex chemical properties. In this work, we develop SMILES2vec, a deep RNN\n",
            "that automatically learns features from SMILES to predict chemical properties,\n",
            "without the need for additional explicit feature engineering. Using Bayesian\n",
            "optimization methods to tune the network architecture, we show that an\n",
            "optimized SMILES2vec model can serve as a general-purpose neural network for\n",
            "predicting distinct chemical properties including toxicity, activity,\n",
            "solubility and solvation energy, while also outperforming contemporary MLP\n",
            "neural networks that uses engineered features. Furthermore, we demonstrate\n",
            "proof-of-concept of interpretability by developing an explanation mask that\n",
            "localizes on the most important characters used in making a prediction. When\n",
            "tested on the solubility dataset, it identified specific parts of a chemical\n",
            "that is consistent with established first-principles knowledge with an accuracy\n",
            "of 88%. Our work demonstrates that neural networks can learn technically\n",
            "accurate chemical concept and provide state-of-the-art accuracy, making\n",
            "interpretable deep neural networks a useful tool of relevance to the chemical\n",
            "industry.\n",
            "Extracted Text:  work demonstrates neural networks learn technically accurate chemical concept provide state art accuracy making interpretable deep neural networks useful tool relevance chemical industry using bayesian optimization methods tune network architecture show optimized smiles vec model serve general purpose neural network predicting distinct chemical properties including toxicity activity energy also outperforming contemporary mlp neural networks uses engineered features furthermore demonstrate proof concept interpretability developing explanation mask localizes important characters used making prediction encoded smiles string structural information used predict complex chemical properties work develop smiles vec deep rnn automatically learns features smiles predict chemical properties without need additional explicit feature engineering chemical databases store information text representations smiles format universal standard used many cheminformatics software tested dataset identified specific parts chemical consistent established first principles knowledge accuracy \n",
            "Original title: SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n",
            "  Predicting Chemical Properties\n",
            "Cleaned summary: vec an interpretable general purpose deep neural network for predicting chemical properties \n",
            "Predicted title:  neural network based model for predicting the quality of\n",
            "\n",
            "\n",
            "Abstract: In spoken dialogue systems, we aim to deploy artificial intelligence to build\n",
            "automated dialogue agents that can converse with humans. A part of this effort\n",
            "is the policy optimisation task, which attempts to find a policy describing how\n",
            "to respond to humans, in the form of a function taking the current state of the\n",
            "dialogue and returning the response of the system. In this paper, we\n",
            "investigate deep reinforcement learning approaches to solve this problem.\n",
            "Particular attention is given to actor-critic methods, off-policy reinforcement\n",
            "learning with experience replay, and various methods aimed at reducing the bias\n",
            "and variance of estimators. When combined, these methods result in the\n",
            "previously proposed ACER algorithm that gave competitive results in gaming\n",
            "environments. These environments however are fully observable and have a\n",
            "relatively small action set so in this paper we examine the application of ACER\n",
            "to dialogue policy optimisation. We show that this method beats the current\n",
            "state-of-the-art in deep learning approaches for spoken dialogue systems. This\n",
            "not only leads to a more sample efficient algorithm that can train faster, but\n",
            "also allows us to apply the algorithm in more difficult environments than\n",
            "before. We thus experiment with learning in a very large action space, which\n",
            "has two orders of magnitude more actions than previously considered. We find\n",
            "that ACER trains significantly faster than the current state-of-the-art.\n",
            "Extracted Text:  part effort policy optimisation task attempts find policy describing respond humans form function taking current state dialogue returning response system environments however fully observable relatively small action set paper examine application dialogue policy optimisation show method beats current state art deep learning approaches spoken dialogue systems thus experiment learning large action space two orders magnitude actions previously considered particular attention given actor critic methods policy reinforcement learning experience replay various methods aimed reducing bias variance estimators paper investigate deep reinforcement learning approaches solve problem combined methods result previously proposed algorithm gave competitive results gaming environments find trains significantly faster current state art leads sample efficient algorithm train faster also allows apply algorithm difficult environments spoken dialogue systems aim deploy artificial intelligence build automated dialogue agents converse humans \n",
            "Original title: Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n",
            "  Large Action Spaces\n",
            "Cleaned summary: sample efficient deep reinforcement learning for dialogue systems with large action spaces \n",
            "Predicted title:  deep reinforcement learning for dialogue state tracking\n",
            "\n",
            "\n",
            "Abstract: With the increasing popularity of video sharing websites such as YouTube and\n",
            "Facebook, multimodal sentiment analysis has received increasing attention from\n",
            "the scientific community. Contrary to previous works in multimodal sentiment\n",
            "analysis which focus on holistic information in speech segments such as bag of\n",
            "words representations and average facial expression intensity, we develop a\n",
            "novel deep architecture for multimodal sentiment analysis that performs\n",
            "modality fusion at the word level. In this paper, we propose the Gated\n",
            "Multimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is\n",
            "composed of 2 modules. The Gated Multimodal Embedding alleviates the\n",
            "difficulties of fusion when there are noisy modalities. The LSTM with Temporal\n",
            "Attention performs word level fusion at a finer fusion resolution between input\n",
            "modalities and attends to the most important time steps. As a result, the\n",
            "GME-LSTM(A) is able to better model the multimodal structure of speech through\n",
            "time and perform better sentiment comprehension. We demonstrate the\n",
            "effectiveness of this approach on the publicly-available Multimodal Corpus of\n",
            "Sentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving\n",
            "state-of-the-art sentiment classification and regression results. Qualitative\n",
            "analysis on our model emphasizes the importance of the Temporal Attention Layer\n",
            "in sentiment prediction because the additional acoustic and visual modalities\n",
            "are noisy. We also demonstrate the effectiveness of the Gated Multimodal\n",
            "Embedding in selectively filtering these noisy modalities out. Our results and\n",
            "analysis open new areas in the study of sentiment analysis in human\n",
            "communication and provide new models for multimodal fusion.\n",
            "Extracted Text:  qualitative analysis model emphasizes importance temporal attention layer sentiment prediction additional acoustic visual modalities noisy contrary previous works multimodal sentiment analysis focus holistic information speech segments bag words representations average facial expression intensity develop novel deep architecture multimodal sentiment analysis performs modality fusion word level results analysis open new areas study sentiment analysis human communication provide new models multimodal fusion lstm temporal attention performs word level fusion finer fusion resolution input modalities attends important time steps demonstrate effectiveness approach publicly available multimodal corpus sentiment intensity subjectivity analysis dataset achieving state art sentiment classification regression results result lstm able better model multimodal structure speech time perform better sentiment comprehension paper propose gated multimodal embedding lstm temporal attention model composed modules increasing popularity video sharing websites youtube facebook multimodal sentiment analysis received increasing attention scientific community also demonstrate effectiveness gated multimodal embedding selectively filtering noisy modalities gated multimodal embedding alleviates difficulties fusion noisy modalities \n",
            "Original title: Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement\n",
            "  Learning\n",
            "Cleaned summary: multimodal sentiment analysis with word level fusion and reinforcement learning \n",
            "Predicted title:  multimodal multimodal fusion for sentiment analysis in multimodal videos\n",
            "\n",
            "\n",
            "Abstract: Temporal common sense has applications in AI tasks such as QA, multi-document\n",
            "summarization, and human-AI communication. We propose the task of sequencing --\n",
            "given a jumbled set of aligned image-caption pairs that belong to a story, the\n",
            "task is to sort them such that the output sequence forms a coherent story. We\n",
            "present multiple approaches, via unary (position) and pairwise (order)\n",
            "predictions, and their ensemble-based combinations, achieving strong results on\n",
            "this task. We use both text-based and image-based features, which depict\n",
            "complementary improvements. Using qualitative examples, we demonstrate that our\n",
            "models have learnt interesting aspects of temporal common sense.\n",
            "Extracted Text:  using qualitative examples demonstrate models learnt interesting aspects temporal common sense use text based image based features depict complementary improvements present multiple approaches via unary pairwise predictions ensemble based combinations achieving strong results task propose task sequencing given set aligned image caption pairs belong story task sort output sequence forms coherent story temporal common sense applications tasks multi document summarization human communication \n",
            "Original title: Sort Story: Sorting Jumbled Images and Captions into Stories\n",
            "Cleaned summary: sort story sorting images and captions into stories \n",
            "Predicted title:  automatic discovery of temporal relations in text\n",
            "\n",
            "\n",
            "Abstract: We propose a simple yet effective technique for neural network learning. The\n",
            "forward propagation is computed as usual. In back propagation, only a small\n",
            "subset of the full gradient is computed to update the model parameters. The\n",
            "gradient vectors are sparsified in such a way that only the top-$k$ elements\n",
            "(in terms of magnitude) are kept. As a result, only $k$ rows or columns\n",
            "(depending on the layout) of the weight matrix are modified, leading to a\n",
            "linear reduction ($k$ divided by the vector dimension) in the computational\n",
            "cost. Surprisingly, experimental results demonstrate that we can update only\n",
            "1--4\\% of the weights at each back propagation pass. This does not result in a\n",
            "larger number of training iterations. More interestingly, the accuracy of the\n",
            "resulting models is actually improved rather than degraded, and a detailed\n",
            "analysis is given. The code is available at https://github.com/jklj077/meProp\n",
            "Extracted Text:  back propagation small subset full gradient computed update model parameters interestingly accuracy resulting models actually improved rather degraded detailed analysis given result rows columns weight matrix modified leading linear reduction computational cost surprisingly experimental results demonstrate update weights back propagation pass result larger number training iterations propose simple yet effective technique neural network learning gradient vectors sparsified way top elements kept forward propagation computed usual code available https github com \n",
            "Original title: meProp: Sparsified Back Propagation for Accelerated Deep Learning with\n",
            "  Reduced Overfitting\n",
            "Cleaned summary: back propagation for accelerated deep learning with reduced overfitting \n",
            "Predicted title:  neural network based inference for feedforward neural networks\n",
            "\n",
            "\n",
            "Abstract: Due to their complex nature, it is hard to characterize the ways in which\n",
            "machine learning models can misbehave or be exploited when deployed. Recent\n",
            "work on adversarial examples, i.e. inputs with minor perturbations that result\n",
            "in substantially different model predictions, is helpful in evaluating the\n",
            "robustness of these models by exposing the adversarial scenarios where they\n",
            "fail. However, these malicious perturbations are often unnatural, not\n",
            "semantically meaningful, and not applicable to complicated domains such as\n",
            "language. In this paper, we propose a framework to generate natural and legible\n",
            "adversarial examples that lie on the data manifold, by searching in semantic\n",
            "space of dense and continuous data representation, utilizing the recent\n",
            "advances in generative adversarial networks. We present generated adversaries\n",
            "to demonstrate the potential of the proposed approach for black-box classifiers\n",
            "for a wide range of applications such as image classification, textual\n",
            "entailment, and machine translation. We include experiments to show that the\n",
            "generated adversaries are natural, legible to humans, and useful in evaluating\n",
            "and analyzing black-box classifiers.\n",
            "Extracted Text:  due complex nature hard characterize ways machine learning models exploited deployed paper propose framework generate natural legible adversarial examples lie data manifold searching semantic space dense continuous data representation utilizing recent advances generative adversarial networks include experiments show generated adversaries natural legible humans useful evaluating analyzing black box classifiers present generated adversaries demonstrate potential proposed approach black box classifiers wide range applications image classification textual entailment machine translation inputs minor perturbations result substantially different model predictions helpful evaluating robustness models exposing adversarial scenarios fail recent work adversarial examples however malicious perturbations often unnatural semantically meaningful applicable complicated domains language \n",
            "Original title: Generating Natural Adversarial Examples\n",
            "Cleaned summary: generating natural adversarial examples \n",
            "Predicted title:  adversarial examples for semantic image classification\n",
            "\n",
            "\n",
            "Abstract: Deep Convolutional Neural Networks (CNNs) are more powerful than Deep Neural\n",
            "Networks (DNN), as they are able to better reduce spectral variation in the\n",
            "input signal. This has also been confirmed experimentally, with CNNs showing\n",
            "improvements in word error rate (WER) between 4-12% relative compared to DNNs\n",
            "across a variety of LVCSR tasks. In this paper, we describe different methods\n",
            "to further improve CNN performance. First, we conduct a deep analysis comparing\n",
            "limited weight sharing and full weight sharing with state-of-the-art features.\n",
            "Second, we apply various pooling strategies that have shown improvements in\n",
            "computer vision to an LVCSR speech task. Third, we introduce a method to\n",
            "effectively incorporate speaker adaptation, namely fMLLR, into log-mel\n",
            "features. Fourth, we introduce an effective strategy to use dropout during\n",
            "Hessian-free sequence training. We find that with these improvements,\n",
            "particularly with fMLLR and dropout, we are able to achieve an additional 2-3%\n",
            "relative improvement in WER on a 50-hour Broadcast News task over our previous\n",
            "best CNN baseline. On a larger 400-hour BN task, we find an additional 4-5%\n",
            "relative improvement over our previous best CNN baseline.\n",
            "Extracted Text:  find improvements particularly dropout able achieve additional relative improvement wer hour broadcast news task previous best cnn baseline second apply various pooling strategies shown improvements computer vision lvcsr speech task first conduct deep analysis comparing limited weight sharing full weight sharing state art features larger hour task find additional relative improvement previous best cnn baseline paper describe different methods improve cnn performance also confirmed experimentally cnns showing improvements word error rate relative compared dnns across variety lvcsr tasks fourth introduce effective strategy use dropout hessian free sequence training third introduce method effectively incorporate speaker adaptation namely log mel features deep convolutional neural networks powerful deep neural networks able better reduce spectral variation input signal \n",
            "Original title: Improvements to deep convolutional neural networks for LVCSR\n",
            "Cleaned summary: improvements to deep convolutional neural networks for lvcsr \n",
            "Predicted title:  deep convolutional neural network for text normalization\n",
            "\n",
            "\n",
            "Abstract: Layer-wise relevance propagation (LRP) is a recently proposed technique for\n",
            "explaining predictions of complex non-linear classifiers in terms of input\n",
            "variables. In this paper, we apply LRP for the first time to natural language\n",
            "processing (NLP). More precisely, we use it to explain the predictions of a\n",
            "convolutional neural network (CNN) trained on a topic categorization task. Our\n",
            "analysis highlights which words are relevant for a specific prediction of the\n",
            "CNN. We compare our technique to standard sensitivity analysis, both\n",
            "qualitatively and quantitatively, using a \"word deleting\" perturbation\n",
            "experiment, a PCA analysis, and various visualizations. All experiments\n",
            "validate the suitability of LRP for explaining the CNN predictions, which is\n",
            "also in line with results reported in recent image classification studies.\n",
            "Extracted Text:  layer wise relevance propagation recently proposed technique explaining predictions complex non linear classifiers terms input variables analysis highlights words relevant specific prediction cnn precisely use explain predictions convolutional neural network trained topic categorization task experiments validate suitability lrp explaining cnn predictions also line results reported recent image classification studies compare technique standard sensitivity analysis qualitatively quantitatively using word deleting perturbation experiment pca analysis various visualizations paper apply lrp first time natural language processing \n",
            "Original title: Explaining Predictions of Non-Linear Classifiers in NLP\n",
            "Cleaned summary: explaining predictions of non linear classifiers in nlp \n",
            "Predicted title:  the of convolutional neural networks\n",
            "\n",
            "\n",
            "Abstract: Linear principal component analysis (PCA) can be extended to a nonlinear PCA\n",
            "by using artificial neural networks. But the benefit of curved components\n",
            "requires a careful control of the model complexity. Moreover, standard\n",
            "techniques for model selection, including cross-validation and more generally\n",
            "the use of an independent test set, fail when applied to nonlinear PCA because\n",
            "of its inherent unsupervised characteristics. This paper presents a new\n",
            "approach for validating the complexity of nonlinear PCA models by using the\n",
            "error in missing data estimation as a criterion for model selection. It is\n",
            "motivated by the idea that only the model of optimal complexity is able to\n",
            "predict missing values with the highest accuracy. While standard test set\n",
            "validation usually favours over-fitted nonlinear PCA models, the proposed model\n",
            "validation approach correctly selects the optimal model complexity.\n",
            "Extracted Text:  moreover standard techniques model selection including cross validation generally use independent test set fail applied nonlinear pca inherent unsupervised characteristics paper presents new approach validating complexity nonlinear pca models using error missing data estimation criterion model selection standard test set validation usually favours fitted nonlinear pca models proposed model validation approach correctly selects optimal model complexity benefit curved components requires careful control model complexity motivated idea model optimal complexity able predict missing values highest accuracy linear principal component analysis extended nonlinear pca using artificial neural networks \n",
            "Original title: Validation of nonlinear PCA\n",
            "Cleaned summary: validation of nonlinear pca \n",
            "Predicted title:  spectral principal component analysis using principal component analysis\n",
            "\n",
            "\n",
            "Abstract: Similarity between objects is multi-faceted and it can be easier for human\n",
            "annotators to measure it when the focus is on a specific aspect. We consider\n",
            "the problem of mapping objects into view-specific embeddings where the distance\n",
            "between them is consistent with the similarity comparisons of the form \"from\n",
            "the t-th view, object A is more similar to B than to C\". Our framework jointly\n",
            "learns view-specific embeddings exploiting correlations between views.\n",
            "Experiments on a number of datasets, including one of multi-view crowdsourced\n",
            "comparison on bird images, show the proposed method achieves lower triplet\n",
            "generalization error when compared to both learning embeddings independently\n",
            "for each view and all views pooled into one view. Our method can also be used\n",
            "to learn multiple measures of similarity over input features taking class\n",
            "labels into account and compares favorably to existing approaches for\n",
            "multi-task metric learning on the ISOLET dataset.\n",
            "Extracted Text:  consider problem mapping objects view specific embeddings distance consistent similarity comparisons form view object similar experiments number datasets including one multi view crowdsourced comparison bird images show proposed method achieves lower triplet generalization error compared learning embeddings independently view views pooled one view method also used learn multiple measures similarity input features taking class labels account compares favorably existing approaches multi task metric learning dataset similarity objects multi faceted easier human annotators measure focus specific aspect framework jointly learns view specific embeddings exploiting correlations views \n",
            "Original title: Jointly Learning Multiple Measures of Similarities from Triplet\n",
            "  Comparisons\n",
            "Cleaned summary: jointly learning multiple measures of similarities from triplet comparisons \n",
            "Predicted title:  multi view metric learning for view matching\n",
            "\n",
            "\n",
            "Abstract: In this paper, we propose a novel unsupervised domain adaptation algorithm\n",
            "based on deep learning for visual object recognition. Specifically, we design a\n",
            "new model called Deep Reconstruction-Classification Network (DRCN), which\n",
            "jointly learns a shared encoding representation for two tasks: i) supervised\n",
            "classification of labeled source data, and ii) unsupervised reconstruction of\n",
            "unlabeled target data.In this way, the learnt representation not only preserves\n",
            "discriminability, but also encodes useful information from the target domain.\n",
            "Our new DRCN model can be optimized by using backpropagation similarly as the\n",
            "standard neural networks.\n",
            "  We evaluate the performance of DRCN on a series of cross-domain object\n",
            "recognition tasks, where DRCN provides a considerable improvement (up to ~8% in\n",
            "accuracy) over the prior state-of-the-art algorithms. Interestingly, we also\n",
            "observe that the reconstruction pipeline of DRCN transforms images from the\n",
            "source domain into images whose appearance resembles the target dataset. This\n",
            "suggests that DRCN's performance is due to constructing a single composite\n",
            "representation that encodes information about both the structure of target\n",
            "images and the classification of source images. Finally, we provide a formal\n",
            "analysis to justify the algorithm's objective in domain adaptation context.\n",
            "Extracted Text:  specifically design new model called deep reconstruction classification network jointly learns shared encoding representation two tasks supervised classification labeled source data unsupervised reconstruction unlabeled target data way learnt representation preserves discriminability also encodes useful information target domain suggests performance due constructing single composite representation encodes information structure target images classification source images evaluate performance series cross domain object recognition tasks provides considerable improvement prior state art algorithms paper propose novel unsupervised domain adaptation algorithm based deep learning visual object recognition finally provide formal analysis justify algorithm objective domain adaptation context interestingly also observe reconstruction pipeline transforms images source domain images whose appearance resembles target dataset new model optimized using backpropagation similarly standard neural networks \n",
            "Original title: Deep Reconstruction-Classification Networks for Unsupervised Domain\n",
            "  Adaptation\n",
            "Cleaned summary: deep reconstruction classification networks for unsupervised domain adaptation \n",
            "Predicted title:  unsupervised learning of visual representations from image\n",
            "\n",
            "\n",
            "Abstract: Finding the most effective way to aggregate multi-subject fMRI data is a\n",
            "long-standing and challenging problem. It is of increasing interest in\n",
            "contemporary fMRI studies of human cognition due to the scarcity of data per\n",
            "subject and the variability of brain anatomy and functional response across\n",
            "subjects. Recent work on latent factor models shows promising results in this\n",
            "task but this approach does not preserve spatial locality in the brain. We\n",
            "examine two ways to combine the ideas of a factor model and a searchlight based\n",
            "analysis to aggregate multi-subject fMRI data while preserving spatial\n",
            "locality. We first do this directly by combining a recent factor method known\n",
            "as a shared response model with searchlight analysis. Then we design a\n",
            "multi-view convolutional autoencoder for the same task. Both approaches\n",
            "preserve spatial locality and have competitive or better performance compared\n",
            "with standard searchlight analysis and the shared response model applied across\n",
            "the whole brain. We also report a system design to handle the computational\n",
            "challenge of training the convolutional autoencoder.\n",
            "Extracted Text:  approaches preserve spatial locality competitive better performance compared standard analysis shared response model applied across whole brain recent work latent factor models shows promising results task approach preserve spatial locality brain examine two ways combine ideas factor model based analysis aggregate multi subject fmri data preserving spatial locality finding effective way aggregate multi subject fmri data long standing challenging problem first directly combining recent factor method known shared response model analysis also report system design handle computational challenge training convolutional autoencoder increasing interest contemporary fmri studies human cognition due scarcity data per subject variability brain anatomy functional response across subjects design multi view convolutional autoencoder task \n",
            "Original title: A Convolutional Autoencoder for Multi-Subject fMRI Data Aggregation\n",
            "Cleaned summary: convolutional autoencoder for multi subject fmri data aggregation \n",
            "Predicted title:  multi view convolutional neural network for brain modelling\n",
            "\n",
            "\n",
            "Abstract: Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT\n",
            "are computationally expensive. To address this problem, we recently proposed\n",
            "the world-first deep convolutional neural network (CNN) for low-dose X-ray CT\n",
            "and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However,\n",
            "some of the texture were not fully recovered. To cope with this problem, here\n",
            "we propose a deep residual learning approach in directional wavelet domain. The\n",
            "proposed method is motivated by an observation that a deep convolutional neural\n",
            "network can be interpreted as a multilayer convolutional framelets expansion\n",
            "using non-local basis convolved with data-driven local basis. We further extend\n",
            "the idea to derive a deep convolutional framelet expansion by combining global\n",
            "redundant transforms and signal boosting from multiple signal representations.\n",
            "Extensive experimental results confirm that the proposed network has\n",
            "significantly improved performance and preserves the detail texture of the\n",
            "original images\n",
            "Extracted Text:  proposed method motivated observation deep convolutional neural network interpreted multilayer convolutional framelets expansion using non local basis convolved data driven local basis extensive experimental results confirm proposed network significantly improved performance preserves detail texture original images address problem recently proposed world first deep convolutional neural network low dose ray second place low dose grand challenge extend idea derive deep convolutional framelet expansion combining global redundant transforms signal boosting multiple signal representations cope problem propose deep residual learning approach directional wavelet domain model based iterative reconstruction algorithms low dose ray computationally expensive however texture fully recovered \n",
            "Original title: Wavelet Residual Network for Low-Dose CT via Deep Convolutional\n",
            "  Framelets\n",
            "Cleaned summary: wavelet residual network for low dose ct via deep convolutional \n",
            "Predicted title:  deep residual learning for compressed sensing of image\n",
            "\n",
            "\n",
            "Abstract: The success of various applications including robotics, digital content\n",
            "creation, and visualization demand a structured and abstract representation of\n",
            "the 3D world from limited sensor data. Inspired by the nature of human\n",
            "perception of 3D shapes as a collection of simple parts, we explore such an\n",
            "abstract shape representation based on primitives. Given a single depth image\n",
            "of an object, we present 3D-PRNN, a generative recurrent neural network that\n",
            "synthesizes multiple plausible shapes composed of a set of primitives. Our\n",
            "generative model encodes symmetry characteristics of common man-made objects,\n",
            "preserves long-range structural coherence, and describes objects of varying\n",
            "complexity with a compact representation. We also propose a method based on\n",
            "Gaussian Fields to generate a large scale dataset of primitive-based shape\n",
            "representations to train our network. We evaluate our approach on a wide range\n",
            "of examples and show that it outperforms nearest-neighbor based shape retrieval\n",
            "methods and is on-par with voxel-based generative models while using a\n",
            "significantly reduced parameter space.\n",
            "Extracted Text:  also propose method based gaussian fields generate large scale dataset primitive based shape representations train network evaluate approach wide range examples show outperforms nearest neighbor based shape retrieval methods par voxel based generative models using significantly reduced parameter space given single depth image object present generative recurrent neural network synthesizes multiple plausible shapes composed set primitives generative model encodes symmetry characteristics common man made objects preserves long range structural coherence describes objects varying complexity compact representation inspired nature human perception shapes collection simple parts explore abstract shape representation based primitives success various applications including robotics digital content creation visualization demand structured abstract representation world limited sensor data \n",
            "Original title: 3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks\n",
            "Cleaned summary: generating shape primitives with recurrent neural networks \n",
            "Predicted title:  learning to generate with generative adversarial networks\n",
            "\n",
            "\n",
            "Abstract: We study the properties of the endpoint of stochastic gradient descent (SGD).\n",
            "By approximating SGD as a stochastic differential equation (SDE) we consider\n",
            "the Boltzmann-Gibbs equilibrium distribution of that SDE under the assumption\n",
            "of isotropic variance in loss gradients. Through this analysis, we find that\n",
            "three factors - learning rate, batch size and the variance of the loss\n",
            "gradients - control the trade-off between the depth and width of the minima\n",
            "found by SGD, with wider minima favoured by a higher ratio of learning rate to\n",
            "batch size. We have direct control over the learning rate and batch size, while\n",
            "the variance is determined by the choice of model architecture, model\n",
            "parameterization and dataset. In the equilibrium distribution only the ratio of\n",
            "learning rate to batch size appears, implying that the equilibrium distribution\n",
            "is invariant under a simultaneous rescaling of learning rate and batch size by\n",
            "the same amount. We then explore experimentally how learning rate and batch\n",
            "size affect SGD from two perspectives: the endpoint of SGD and the dynamics\n",
            "that lead up to it. For the endpoint, the experiments suggest the endpoint of\n",
            "SGD is invariant under simultaneous rescaling of batch size and learning rate,\n",
            "and also that a higher ratio leads to flatter minima, both findings are\n",
            "consistent with our theoretical analysis. We note experimentally that the\n",
            "dynamics also seem to be invariant under the same rescaling of learning rate\n",
            "and batch size, which we explore showing that one can exchange batch size and\n",
            "learning rate for cyclical learning rate schedule. Next, we illustrate how\n",
            "noise affects memorization, showing that high noise levels lead to better\n",
            "generalization. Finally, we find experimentally that the invariance under\n",
            "simultaneous rescaling of learning rate and batch size breaks down if the\n",
            "learning rate gets too large or the batch size gets too small.\n",
            "Extracted Text:  equilibrium distribution ratio learning rate batch size appears implying equilibrium distribution invariant simultaneous rescaling learning rate batch size amount analysis find three factors learning rate batch size variance loss gradients control trade depth width minima found sgd wider minima favoured higher ratio learning rate batch size note experimentally dynamics also seem invariant rescaling learning rate batch size explore showing one exchange batch size learning rate cyclical learning rate schedule endpoint experiments suggest endpoint sgd invariant simultaneous rescaling batch size learning rate also higher ratio leads minima findings consistent theoretical analysis direct control learning rate batch size variance determined choice model architecture model parameterization dataset explore experimentally learning rate batch size affect sgd two perspectives endpoint sgd dynamics lead finally find experimentally invariance simultaneous rescaling learning rate batch size breaks learning rate gets large batch size gets small next illustrate noise affects memorization showing high noise levels lead better generalization study properties endpoint stochastic gradient descent approximating sgd stochastic differential equation consider boltzmann gibbs equilibrium distribution assumption isotropic variance loss gradients \n",
            "Original title: Three Factors Influencing Minima in SGD\n",
            "Cleaned summary: three factors minima in sgd \n",
            "Predicted title:  gradient descent for learning stochastic gradient descent\n",
            "\n",
            "\n",
            "Abstract: Generating video frames that accurately predict future world states is\n",
            "challenging. Existing approaches either fail to capture the full distribution\n",
            "of outcomes, or yield blurry generations, or both. In this paper we introduce\n",
            "an unsupervised video generation model that learns a prior model of uncertainty\n",
            "in a given environment. Video frames are generated by drawing samples from this\n",
            "prior and combining them with a deterministic estimate of the future frame. The\n",
            "approach is simple and easily trained end-to-end on a variety of datasets.\n",
            "Sample generations are both varied and sharp, even many frames into the future,\n",
            "and compare favorably to those from existing approaches.\n",
            "Extracted Text:  sample generations varied sharp even many frames future compare favorably existing approaches generating video frames accurately predict future world states challenging video frames generated drawing samples prior combining deterministic estimate future frame existing approaches either fail capture full distribution outcomes yield blurry generations paper introduce unsupervised video generation model learns prior model uncertainty given environment approach simple easily trained end end variety datasets \n",
            "Original title: Stochastic Video Generation with a Learned Prior\n",
            "Cleaned summary: stochastic video generation with learned prior \n",
            "Predicted title:  unsupervised video video generation using unsupervised learning\n",
            "\n",
            "\n",
            "Abstract: The speech code is a vehicle of language: it defines a set of forms used by a\n",
            "community to carry information. Such a code is necessary to support the\n",
            "linguistic interactions that allow humans to communicate. How then may a speech\n",
            "code be formed prior to the existence of linguistic interactions? Moreover, the\n",
            "human speech code is discrete and compositional, shared by all the individuals\n",
            "of a community but different across communities, and phoneme inventories are\n",
            "characterized by statistical regularities. How can a speech code with these\n",
            "properties form? We try to approach these questions in the paper, using the\n",
            "\"methodology of the artificial\". We build a society of artificial agents, and\n",
            "detail a mechanism that shows the formation of a discrete speech code without\n",
            "pre-supposing the existence of linguistic capacities or of coordinated\n",
            "interactions. The mechanism is based on a low-level model of sensory-motor\n",
            "interactions. We show that the integration of certain very simple and non\n",
            "language-specific neural devices leads to the formation of a speech code that\n",
            "has properties similar to the human speech code. This result relies on the\n",
            "self-organizing properties of a generic coupling between perception and\n",
            "production within agents, and on the interactions between agents. The\n",
            "artificial system helps us to develop better intuitions on how speech might\n",
            "have appeared, by showing how self-organization might have helped natural\n",
            "selection to find speech.\n",
            "Extracted Text:  show integration certain simple non language specific neural devices leads formation speech code properties similar human speech code build society artificial agents detail mechanism shows formation discrete speech code without pre supposing existence linguistic capacities coordinated interactions speech code vehicle language defines set forms used community carry information may speech code formed prior existence linguistic interactions moreover human speech code discrete compositional shared individuals community different across communities phoneme inventories characterized statistical regularities artificial system helps develop better intuitions speech might appeared showing self organization might helped natural selection find speech code necessary support linguistic interactions allow humans communicate result relies self organizing properties generic coupling perception production within agents interactions agents speech code properties form try approach questions paper using methodology artificial \n",
            "Original title: The Self-Organization of Speech Sounds\n",
            "Cleaned summary: the self organization of speech sounds \n",
            "Predicted title:  speech synthesis for speech to speech synthesis\n",
            "\n",
            "\n",
            "Abstract: Despite significant progress in object categorization, in recent years, a\n",
            "number of important challenges remain, mainly, ability to learn from limited\n",
            "labeled data and ability to recognize object classes within large, potentially\n",
            "open, set of labels. Zero-shot learning is one way of addressing these\n",
            "challenges, but it has only been shown to work with limited sized class\n",
            "vocabularies and typically requires separation between supervised and\n",
            "unsupervised classes, allowing former to inform the latter but not vice versa.\n",
            "We propose the notion of semi-supervised vocabulary-informed learning to\n",
            "alleviate the above mentioned challenges and address problems of supervised,\n",
            "zero-shot and open set recognition using a unified framework. Specifically, we\n",
            "propose a maximum margin framework for semantic manifold-based recognition that\n",
            "incorporates distance constraints from (both supervised and unsupervised)\n",
            "vocabulary atoms, ensuring that labeled samples are projected closest to their\n",
            "correct prototypes, in the embedding space, than to others. We show that\n",
            "resulting model shows improvements in supervised, zero-shot, and large open set\n",
            "recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.\n",
            "Extracted Text:  despite significant progress object categorization recent years number important challenges remain mainly ability learn limited labeled data ability recognize object classes within large potentially open set labels zero shot learning one way addressing challenges shown work limited sized class vocabularies typically requires separation supervised unsupervised classes allowing former inform latter vice versa propose notion semi supervised vocabulary informed learning alleviate mentioned challenges address problems supervised zero shot open set recognition using unified framework show resulting model shows improvements supervised zero shot large open set recognition class vocabulary awa imagenet datasets specifically propose maximum margin framework semantic manifold based recognition incorporates distance constraints vocabulary atoms ensuring labeled samples projected closest correct prototypes embedding space others \n",
            "Original title: Semi-supervised Vocabulary-informed Learning\n",
            "Cleaned summary: semi supervised vocabulary informed learning \n",
            "Predicted title:  learning to learn zero shot features\n",
            "\n",
            "\n",
            "Abstract: We propose an intuitive generalization to the Generative Adversarial Networks\n",
            "(GANs) and its conditional variants to address the well known mode collapse\n",
            "problem. Firstly, we propose a multi-agent GAN architecture incorporating\n",
            "multiple generators and one discriminator. Secondly, to enforce different\n",
            "generators to capture diverse high probability modes, we modify discriminator's\n",
            "objective function where along with finding the real and fake samples, the\n",
            "discriminator has to identify the generator that generated the fake sample.\n",
            "Intuitively, to succeed in this task, the discriminator must learn to push\n",
            "different generators towards different identifiable modes. Our framework\n",
            "(MAD-GAN) is generalizable in the sense that it can be easily combined with\n",
            "other existing variants of GANs to produce diverse samples. We perform\n",
            "extensive experiments on synthetic and real datasets and compare MAD-GAN with\n",
            "different variants of GAN. We show high quality diverse sample generations for\n",
            "the challenging tasks such as image-to-image translation (known to learn delta\n",
            "distribution) and face generation. In addition, we show that MAD-GAN is able to\n",
            "disentangle different modalities even when trained using highly challenging\n",
            "multi-view dataset (mixture of forests, icebergs, bedrooms etc). In the end, we\n",
            "also show its efficacy for the unsupervised feature representation task. In the\n",
            "appendix we introduce a similarity based competing objective which encourages\n",
            "the different generators to generate varied samples judged by a user defined\n",
            "similarity metric. We show extensive evaluations on a 1-D setting of mixture of\n",
            "gaussians for non parametric density estimation. The theoretical proofs back\n",
            "the efficacy of the framework and explains why various generators are pushed\n",
            "towards distinct clusters of modes.\n",
            "Extracted Text:  appendix introduce similarity based competing objective encourages different generators generate varied samples judged user defined similarity metric addition show mad gan able disentangle different modalities even trained using highly challenging multi view dataset secondly enforce different generators capture diverse high probability modes modify discriminator objective function along finding real fake samples discriminator identify generator generated fake sample theoretical proofs back efficacy framework explains various generators pushed towards distinct clusters modes intuitively succeed task discriminator must learn push different generators towards different identifiable modes framework generalizable sense easily combined existing variants gans produce diverse samples show high quality diverse sample generations challenging tasks image image translation face generation propose intuitive generalization generative adversarial networks conditional variants address well known mode collapse problem end also show efficacy unsupervised feature representation task firstly propose multi agent gan architecture incorporating multiple generators one discriminator \n",
            "Original title: Multi-Agent Diverse Generative Adversarial Networks\n",
            "Cleaned summary: multi agent diverse generative adversarial networks \n",
            "Predicted title:  generative adversarial network for image translation\n",
            "\n",
            "\n",
            "Abstract: In many real-world scenarios, rewards extrinsic to the agent are extremely\n",
            "sparse, or absent altogether. In such cases, curiosity can serve as an\n",
            "intrinsic reward signal to enable the agent to explore its environment and\n",
            "learn skills that might be useful later in its life. We formulate curiosity as\n",
            "the error in an agent's ability to predict the consequence of its own actions\n",
            "in a visual feature space learned by a self-supervised inverse dynamics model.\n",
            "Our formulation scales to high-dimensional continuous state spaces like images,\n",
            "bypasses the difficulties of directly predicting pixels, and, critically,\n",
            "ignores the aspects of the environment that cannot affect the agent. The\n",
            "proposed approach is evaluated in two environments: VizDoom and Super Mario\n",
            "Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where\n",
            "curiosity allows for far fewer interactions with the environment to reach the\n",
            "goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent\n",
            "to explore more efficiently; and 3) generalization to unseen scenarios (e.g.\n",
            "new levels of the same game) where the knowledge gained from earlier experience\n",
            "helps the agent explore new places much faster than starting from scratch. Demo\n",
            "video and code available at https://pathak22.github.io/noreward-rl/\n",
            "Extracted Text:  proposed approach evaluated two environments vizdoom super mario bros three broad settings investigated sparse extrinsic reward curiosity allows far fewer interactions environment reach goal exploration extrinsic reward curiosity pushes agent explore efficiently generalization unseen scenarios knowledge gained earlier experience helps agent explore new places much faster starting scratch many real world scenarios rewards extrinsic agent extremely sparse absent altogether demo video code available https github \n",
            "Original title: Curiosity-driven Exploration by Self-supervised Prediction\n",
            "Cleaned summary: curiosity driven exploration by self supervised prediction \n",
            "Predicted title:  the computational model of human brain\n",
            "\n",
            "\n",
            "Abstract: Generating adversarial examples is a critical step for evaluating and\n",
            "improving the robustness of learning machines. So far, most existing methods\n",
            "only work for classification and are not designed to alter the true performance\n",
            "measure of the problem at hand. We introduce a novel flexible approach named\n",
            "Houdini for generating adversarial examples specifically tailored for the final\n",
            "performance measure of the task considered, be it combinatorial and\n",
            "non-decomposable. We successfully apply Houdini to a range of applications such\n",
            "as speech recognition, pose estimation and semantic segmentation. In all cases,\n",
            "the attacks based on Houdini achieve higher success rate than those based on\n",
            "the traditional surrogates used to train the models while using a less\n",
            "perceptible adversarial perturbation.\n",
            "Extracted Text:  far existing methods work classification designed alter true performance measure problem hand introduce novel flexible approach named generating adversarial examples specifically tailored final performance measure task considered combinatorial non decomposable cases attacks based achieve higher success rate based traditional surrogates used train models using less perceptible adversarial perturbation generating adversarial examples critical step evaluating improving robustness learning machines successfully apply range applications speech recognition pose estimation semantic segmentation \n",
            "Original title: Houdini: Fooling Deep Structured Prediction Models\n",
            "Cleaned summary: deep structured prediction models \n",
            "Predicted title:  adversarial examples for semantic segmentation\n",
            "\n",
            "\n",
            "Abstract: Dropout is a simple but effective technique for learning in neural networks\n",
            "and other settings. A sound theoretical understanding of dropout is needed to\n",
            "determine when dropout should be applied and how to use it most effectively. In\n",
            "this paper we continue the exploration of dropout as a regularizer pioneered by\n",
            "Wager, et.al. We focus on linear classification where a convex proxy to the\n",
            "misclassification loss (i.e. the logistic loss used in logistic regression) is\n",
            "minimized. We show: (a) when the dropout-regularized criterion has a unique\n",
            "minimizer, (b) when the dropout-regularization penalty goes to infinity with\n",
            "the weights, and when it remains bounded, (c) that the dropout regularization\n",
            "can be non-monotonic as individual weights increase from 0, and (d) that the\n",
            "dropout regularization penalty may not be convex. This last point is\n",
            "particularly surprising because the combination of dropout regularization with\n",
            "any convex loss proxy is always a convex function.\n",
            "  In order to contrast dropout regularization with $L_2$ regularization, we\n",
            "formalize the notion of when different sources are more compatible with\n",
            "different regularizers. We then exhibit distributions that are provably more\n",
            "compatible with dropout regularization than $L_2$ regularization, and vice\n",
            "versa. These sources provide additional insight into how the inductive biases\n",
            "of dropout and $L_2$ regularization differ. We provide some similar results for\n",
            "$L_1$ regularization.\n",
            "Extracted Text:  order contrast dropout regularization regularization formalize notion different sources compatible different regularizers provide similar results regularization sound theoretical understanding dropout needed determine dropout applied use effectively last point particularly surprising combination dropout regularization convex loss proxy always convex function show dropout regularized criterion unique minimizer dropout regularization penalty goes infinity weights remains bounded dropout regularization non monotonic individual weights increase dropout regularization penalty may convex dropout simple effective technique learning neural networks settings sources provide additional insight inductive biases dropout regularization differ focus linear classification convex proxy misclassification loss minimized \n",
            "Original title: On the Inductive Bias of Dropout\n",
            "Cleaned summary: on the inductive bias of dropout \n",
            "Predicted title:  gradient descent for regularization\n",
            "\n",
            "\n",
            "Abstract: Measuring the morphological parameters of galaxies is a key requirement for\n",
            "studying their formation and evolution. Surveys such as the Sloan Digital Sky\n",
            "Survey (SDSS) have resulted in the availability of very large collections of\n",
            "images, which have permitted population-wide analyses of galaxy morphology.\n",
            "Morphological analysis has traditionally been carried out mostly via visual\n",
            "inspection by trained experts, which is time-consuming and does not scale to\n",
            "large ($\\gtrsim10^4$) numbers of images.\n",
            "  Although attempts have been made to build automated classification systems,\n",
            "these have not been able to achieve the desired level of accuracy. The Galaxy\n",
            "Zoo project successfully applied a crowdsourcing strategy, inviting online\n",
            "users to classify images by answering a series of questions. Unfortunately,\n",
            "even this approach does not scale well enough to keep up with the increasing\n",
            "availability of galaxy images.\n",
            "  We present a deep neural network model for galaxy morphology classification\n",
            "which exploits translational and rotational symmetry. It was developed in the\n",
            "context of the Galaxy Challenge, an international competition to build the best\n",
            "model for morphology classification based on annotated images from the Galaxy\n",
            "Zoo project.\n",
            "  For images with high agreement among the Galaxy Zoo participants, our model\n",
            "is able to reproduce their consensus with near-perfect accuracy ($> 99\\%$) for\n",
            "most questions. Confident model predictions are highly accurate, which makes\n",
            "the model suitable for filtering large collections of images and forwarding\n",
            "challenging images to experts for manual annotation. This approach greatly\n",
            "reduces the experts' workload without affecting accuracy. The application of\n",
            "these algorithms to larger sets of training data will be critical for analysing\n",
            "results from future surveys such as the LSST.\n",
            "Extracted Text:  morphological analysis traditionally carried mostly via visual inspection trained experts time consuming scale large numbers images unfortunately even approach scale well enough keep increasing availability galaxy images images high agreement among galaxy zoo participants model able reproduce consensus near perfect accuracy questions application algorithms larger sets training data critical analysing results future surveys confident model predictions highly accurate makes model suitable filtering large collections images forwarding challenging images experts manual annotation although attempts made build automated classification systems able achieve desired level accuracy developed context galaxy challenge international competition build best model morphology classification based annotated images galaxy zoo project surveys sloan digital sky survey resulted availability large collections images permitted population wide analyses galaxy morphology galaxy zoo project successfully applied crowdsourcing strategy inviting online users classify images answering series questions measuring morphological parameters galaxies key requirement studying formation evolution \n",
            "Original title: Rotation-invariant convolutional neural networks for galaxy morphology\n",
            "  prediction\n",
            "Cleaned summary: rotation invariant convolutional neural networks for galaxy morphology prediction \n",
            "Predicted title:  the system for the automatic assessment of arabic\n",
            "\n",
            "\n",
            "Abstract: We propose Neural Responding Machine (NRM), a neural network-based response\n",
            "generator for Short-Text Conversation. NRM takes the general encoder-decoder\n",
            "framework: it formalizes the generation of response as a decoding process based\n",
            "on the latent representation of the input text, while both encoding and\n",
            "decoding are realized with recurrent neural networks (RNN). The NRM is trained\n",
            "with a large amount of one-round conversation data collected from a\n",
            "microblogging service. Empirical study shows that NRM can generate\n",
            "grammatically correct and content-wise appropriate responses to over 75% of the\n",
            "input text, outperforming state-of-the-arts in the same setting, including\n",
            "retrieval-based and SMT-based models.\n",
            "Extracted Text:  empirical study shows generate grammatically correct content wise appropriate responses input text outperforming state arts setting including retrieval based smt based models propose neural responding machine neural network based response generator short text conversation takes general encoder decoder framework formalizes generation response decoding process based latent representation input text encoding decoding realized recurrent neural networks trained large amount one round conversation data collected microblogging service \n",
            "Original title: Neural Responding Machine for Short-Text Conversation\n",
            "Cleaned summary: neural machine for short text conversation \n",
            "Predicted title:  neural network based conversation model for predicting user preferences in chinese\n",
            "\n",
            "\n",
            "Abstract: Recurrent neural networks, and in particular long short-term memory (LSTM)\n",
            "networks, are a remarkably effective tool for sequence modeling that learn a\n",
            "dense black-box hidden representation of their sequential input. Researchers\n",
            "interested in better understanding these models have studied the changes in\n",
            "hidden state representations over time and noticed some interpretable patterns\n",
            "but also significant noise. In this work, we present LSTMVIS, a visual analysis\n",
            "tool for recurrent neural networks with a focus on understanding these hidden\n",
            "state dynamics. The tool allows users to select a hypothesis input range to\n",
            "focus on local state changes, to match these states changes to similar patterns\n",
            "in a large data set, and to align these results with structural annotations\n",
            "from their domain. We show several use cases of the tool for analyzing specific\n",
            "hidden state properties on dataset containing nesting, phrase structure, and\n",
            "chord progressions, and demonstrate how the tool can be used to isolate\n",
            "patterns for further statistical analysis. We characterize the domain, the\n",
            "different stakeholders, and their goals and tasks.\n",
            "Extracted Text:  tool allows users select hypothesis input range focus local state changes match states changes similar patterns large data set align results structural annotations domain work present visual analysis tool recurrent neural networks focus understanding hidden state dynamics show several use cases tool analyzing specific hidden state properties dataset containing nesting phrase structure chord progressions demonstrate tool used isolate patterns statistical analysis recurrent neural networks particular long short term memory networks remarkably effective tool sequence modeling learn dense black box hidden representation sequential input researchers interested better understanding models studied changes hidden state representations time noticed interpretable patterns also significant noise characterize domain different stakeholders goals tasks \n",
            "Original title: LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in\n",
            "  Recurrent Neural Networks\n",
            "Cleaned summary: tool for visual analysis of hidden state dynamics in recurrent neural networks \n",
            "Predicted title:  learning to generate with recurrent neural networks\n",
            "\n",
            "\n",
            "Abstract: Natural Language Inference is an important task for Natural Language\n",
            "Understanding. It is concerned with classifying the logical relation between\n",
            "two sentences. In this paper, we propose several text generative neural\n",
            "networks for generating text hypothesis, which allows construction of new\n",
            "Natural Language Inference datasets. To evaluate the models, we propose a new\n",
            "metric -- the accuracy of the classifier trained on the generated dataset. The\n",
            "accuracy obtained by our best generative model is only 2.7% lower than the\n",
            "accuracy of the classifier trained on the original, human crafted dataset.\n",
            "Furthermore, the best generated dataset combined with the original dataset\n",
            "achieves the highest accuracy. The best model learns a mapping embedding for\n",
            "each training example. By comparing various metrics we show that datasets that\n",
            "obtain higher ROUGE or METEOR scores do not necessarily yield higher\n",
            "classification accuracies. We also provide analysis of what are the\n",
            "characteristics of a good dataset including the distinguishability of the\n",
            "generated datasets from the original one.\n",
            "Extracted Text:  also provide analysis characteristics good dataset including distinguishability generated datasets original one accuracy obtained best generative model lower accuracy classifier trained original human crafted dataset paper propose several text generative neural networks generating text hypothesis allows construction new natural language inference datasets evaluate models propose new metric accuracy classifier trained generated dataset comparing various metrics show datasets obtain higher rouge meteor scores necessarily yield higher classification accuracies furthermore best generated dataset combined original dataset achieves highest accuracy best model learns mapping embedding training example natural language inference important task natural language understanding concerned classifying logical relation two sentences \n",
            "Original title: Constructing a Natural Language Inference Dataset using Generative\n",
            "  Neural Networks\n",
            "Cleaned summary: constructing natural language inference dataset using generative neural networks \n",
            "Predicted title:  neural network based abstract for text summarization\n",
            "\n",
            "\n",
            "Abstract: Neural network-based systems can now learn to locate the referents of words\n",
            "and phrases in images, answer questions about visual scenes, and even execute\n",
            "symbolic instructions as first-person actors in partially-observable worlds. To\n",
            "achieve this so-called grounded language learning, models must overcome certain\n",
            "well-studied learning challenges that are also fundamental to infants learning\n",
            "their first words. While it is notable that models with no meaningful prior\n",
            "knowledge overcome these learning obstacles, AI researchers and practitioners\n",
            "currently lack a clear understanding of exactly how they do so. Here we address\n",
            "this question as a way of achieving a clearer general understanding of grounded\n",
            "language learning, both to inform future research and to improve confidence in\n",
            "model predictions. For maximum control and generality, we focus on a simple\n",
            "neural network-based language learning agent trained via policy-gradient\n",
            "methods to interpret synthetic linguistic instructions in a simulated 3D world.\n",
            "We apply experimental paradigms from developmental psychology to this agent,\n",
            "exploring the conditions under which established human biases and learning\n",
            "effects emerge. We further propose a novel way to visualise and analyse\n",
            "semantic representation in grounded language learning agents that yields a\n",
            "plausible computational account of the observed effects.\n",
            "Extracted Text:  achieve called grounded language learning models must overcome certain well studied learning challenges also fundamental infants learning first words notable models meaningful prior knowledge overcome learning obstacles researchers practitioners currently lack clear understanding exactly maximum control generality focus simple neural network based language learning agent trained via policy gradient methods interpret synthetic linguistic instructions simulated world propose novel way visualise analyse semantic representation grounded language learning agents yields plausible computational account observed effects address question way achieving clearer general understanding grounded language learning inform future research improve confidence model predictions neural network based systems learn locate referents words phrases images answer questions visual scenes even execute symbolic instructions first person actors partially observable worlds apply experimental paradigms developmental psychology agent exploring conditions established human biases learning effects emerge \n",
            "Original title: Understanding Grounded Language Learning Agents\n",
            "Cleaned summary: understanding grounded language learning agents \n",
            "Predicted title:  learning to generate natural language from natural language\n",
            "\n",
            "\n",
            "Abstract: We propose a spatial diffuseness feature for deep neural network (DNN)-based\n",
            "automatic speech recognition to improve recognition accuracy in reverberant and\n",
            "noisy environments. The feature is computed in real-time from multiple\n",
            "microphone signals without requiring knowledge or estimation of the direction\n",
            "of arrival, and represents the relative amount of diffuse noise in each time\n",
            "and frequency bin. It is shown that using the diffuseness feature as an\n",
            "additional input to a DNN-based acoustic model leads to a reduced word error\n",
            "rate for the REVERB challenge corpus, both compared to logmelspec features\n",
            "extracted from noisy signals, and features enhanced by spectral subtraction.\n",
            "Extracted Text:  shown using feature additional input dnn based acoustic model leads reduced word error rate challenge corpus compared features extracted noisy signals features enhanced spectral subtraction feature computed real time multiple microphone signals without requiring knowledge estimation direction arrival represents relative amount diffuse noise time frequency bin propose spatial feature deep neural network based automatic speech recognition improve recognition accuracy reverberant noisy environments \n",
            "Original title: Spatial Diffuseness Features for DNN-Based Speech Recognition in Noisy\n",
            "  and Reverberant Environments\n",
            "Cleaned summary: spatial features for dnn based speech recognition in noisy and environments \n",
            "Predicted title:  robust speech recognition using deep neural network\n",
            "\n",
            "\n",
            "Abstract: We present a method to perform first-pass large vocabulary continuous speech\n",
            "recognition using only a neural network and language model. Deep neural network\n",
            "acoustic models are now commonplace in HMM-based speech recognition systems,\n",
            "but building such systems is a complex, domain-specific task. Recent work\n",
            "demonstrated the feasibility of discarding the HMM sequence modeling framework\n",
            "by directly predicting transcript text from audio. This paper extends this\n",
            "approach in two ways. First, we demonstrate that a straightforward recurrent\n",
            "neural network architecture can achieve a high level of accuracy. Second, we\n",
            "propose and evaluate a modified prefix-search decoding algorithm. This approach\n",
            "to decoding enables first-pass speech recognition with a language model,\n",
            "completely unaided by the cumbersome infrastructure of HMM-based systems.\n",
            "Experiments on the Wall Street Journal corpus demonstrate fairly competitive\n",
            "word error rates, and the importance of bi-directional network recurrence.\n",
            "Extracted Text:  present method perform first pass large vocabulary continuous speech recognition using neural network language model approach decoding enables first pass speech recognition language model completely unaided cumbersome infrastructure hmm based systems deep neural network acoustic models commonplace hmm based speech recognition systems building systems complex domain specific task first demonstrate straightforward recurrent neural network architecture achieve high level accuracy experiments wall street journal corpus demonstrate fairly competitive word error rates importance directional network recurrence recent work demonstrated feasibility discarding hmm sequence modeling framework directly predicting transcript text audio paper extends approach two ways second propose evaluate modified prefix search decoding algorithm \n",
            "Original title: First-Pass Large Vocabulary Continuous Speech Recognition using\n",
            "  Bi-Directional Recurrent DNNs\n",
            "Cleaned summary: first pass large vocabulary continuous speech recognition using bi directional recurrent dnns \n",
            "Predicted title:  neural network based speech recognition\n",
            "\n",
            "\n",
            "Abstract: Recently, strong results have been demonstrated by Deep Recurrent Neural\n",
            "Networks on natural language transduction problems. In this paper we explore\n",
            "the representational power of these models using synthetic grammars designed to\n",
            "exhibit phenomena similar to those found in real transduction problems such as\n",
            "machine translation. These experiments lead us to propose new memory-based\n",
            "recurrent networks that implement continuously differentiable analogues of\n",
            "traditional data structures such as Stacks, Queues, and DeQues. We show that\n",
            "these architectures exhibit superior generalisation performance to Deep RNNs\n",
            "and are often able to learn the underlying generating algorithms in our\n",
            "transduction experiments.\n",
            "Extracted Text:  show architectures exhibit superior generalisation performance deep rnns often able learn underlying generating algorithms transduction experiments paper explore representational power models using synthetic grammars designed exhibit phenomena similar found real transduction problems machine translation experiments lead propose new memory based recurrent networks implement continuously differentiable analogues traditional data structures stacks queues recently strong results demonstrated deep recurrent neural networks natural language transduction problems \n",
            "Original title: Learning to Transduce with Unbounded Memory\n",
            "Cleaned summary: learning to with unbounded memory \n",
            "Predicted title:  recurrent neural networks with limited memory\n",
            "\n",
            "\n",
            "Abstract: We propose zoneout, a novel method for regularizing RNNs. At each timestep,\n",
            "zoneout stochastically forces some hidden units to maintain their previous\n",
            "values. Like dropout, zoneout uses random noise to train a pseudo-ensemble,\n",
            "improving generalization. But by preserving instead of dropping hidden units,\n",
            "gradient information and state information are more readily propagated through\n",
            "time, as in feedforward stochastic depth networks. We perform an empirical\n",
            "investigation of various RNN regularizers, and find that zoneout gives\n",
            "significant performance improvements across tasks. We achieve competitive\n",
            "results with relatively simple models in character- and word-level language\n",
            "modelling on the Penn Treebank and Text8 datasets, and combining with recurrent\n",
            "batch normalization yields state-of-the-art results on permuted sequential\n",
            "MNIST.\n",
            "Extracted Text:  achieve competitive results relatively simple models character word level language modelling penn treebank text datasets combining recurrent batch normalization yields state art results permuted sequential mnist perform empirical investigation various rnn regularizers find gives significant performance improvements across tasks preserving instead dropping hidden units gradient information state information readily propagated time feedforward stochastic depth networks like dropout uses random noise train pseudo ensemble improving generalization timestep stochastically forces hidden units maintain previous values propose novel method regularizing rnns \n",
            "Original title: Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations\n",
            "Cleaned summary: regularizing rnns by randomly preserving hidden activations \n",
            "Predicted title:  stochastic recurrent neural network for language modeling\n",
            "\n",
            "\n",
            "Abstract: This paper develops a model that addresses sentence embedding, a hot topic in\n",
            "current natural language processing research, using recurrent neural networks\n",
            "with Long Short-Term Memory (LSTM) cells. Due to its ability to capture long\n",
            "term memory, the LSTM-RNN accumulates increasingly richer information as it\n",
            "goes through the sentence, and when it reaches the last word, the hidden layer\n",
            "of the network provides a semantic representation of the whole sentence. In\n",
            "this paper, the LSTM-RNN is trained in a weakly supervised manner on user\n",
            "click-through data logged by a commercial web search engine. Visualization and\n",
            "analysis are performed to understand how the embedding process works. The model\n",
            "is found to automatically attenuate the unimportant words and detects the\n",
            "salient keywords in the sentence. Furthermore, these detected keywords are\n",
            "found to automatically activate different cells of the LSTM-RNN, where words\n",
            "belonging to a similar topic activate the same cell. As a semantic\n",
            "representation of the sentence, the embedding vector can be used in many\n",
            "different applications. These automatic keyword detection and topic allocation\n",
            "abilities enabled by the LSTM-RNN allow the network to perform document\n",
            "retrieval, a difficult language processing task, where the similarity between\n",
            "the query and documents can be measured by the distance between their\n",
            "corresponding sentence embedding vectors computed by the LSTM-RNN. On a web\n",
            "search task, the LSTM-RNN embedding is shown to significantly outperform\n",
            "several existing state of the art methods. We emphasize that the proposed model\n",
            "generates sentence embedding vectors that are specially useful for web document\n",
            "retrieval tasks. A comparison with a well known general sentence embedding\n",
            "method, the Paragraph Vector, is performed. The results show that the proposed\n",
            "method in this paper significantly outperforms it for web document retrieval\n",
            "task.\n",
            "Extracted Text:  emphasize proposed model generates sentence embedding vectors specially useful web document retrieval tasks automatic keyword detection topic allocation abilities enabled lstm rnn allow network perform document retrieval difficult language processing task similarity query documents measured distance corresponding sentence embedding vectors computed lstm rnn paper develops model addresses sentence embedding hot topic current natural language processing research using recurrent neural networks long short term memory cells web search task lstm rnn embedding shown significantly outperform several existing state art methods results show proposed method paper significantly outperforms web document retrieval task semantic representation sentence embedding vector used many different applications due ability capture long term memory lstm rnn accumulates increasingly richer information goes sentence reaches last word hidden layer network provides semantic representation whole sentence comparison well known general sentence embedding method paragraph vector performed paper lstm rnn trained weakly supervised manner user click data logged commercial web search engine visualization analysis performed understand embedding process works \n",
            "Original title: Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis\n",
            "  and Application to Information Retrieval\n",
            "Cleaned summary: sentence embedding using long short term memory networks analysis and application to information retrieval \n",
            "Predicted title:  neural network based document retrieval\n",
            "\n",
            "\n",
            "Abstract: Most tasks in natural language processing can be cast into question answering\n",
            "(QA) problems over language input. We introduce the dynamic memory network\n",
            "(DMN), a neural network architecture which processes input sequences and\n",
            "questions, forms episodic memories, and generates relevant answers. Questions\n",
            "trigger an iterative attention process which allows the model to condition its\n",
            "attention on the inputs and the result of previous iterations. These results\n",
            "are then reasoned over in a hierarchical recurrent sequence model to generate\n",
            "answers. The DMN can be trained end-to-end and obtains state-of-the-art results\n",
            "on several types of tasks and datasets: question answering (Facebook's bAbI\n",
            "dataset), text classification for sentiment analysis (Stanford Sentiment\n",
            "Treebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The\n",
            "training for these different tasks relies exclusively on trained word vector\n",
            "representations and input-question-answer triplets.\n",
            "Extracted Text:  dmn trained end end obtains state art results several types tasks datasets question answering text classification sentiment analysis sequence modeling part speech tagging introduce dynamic memory network neural network architecture processes input sequences questions forms episodic memories generates relevant answers tasks natural language processing cast question answering problems language input questions trigger iterative attention process allows model condition attention inputs result previous iterations training different tasks relies exclusively trained word vector representations input question answer triplets results reasoned hierarchical recurrent sequence model generate answers \n",
            "Original title: Ask Me Anything: Dynamic Memory Networks for Natural Language Processing\n",
            "Cleaned summary: ask me dynamic memory networks for natural language processing \n",
            "Predicted title:  attention based question answering with attention\n",
            "\n",
            "\n",
            "Abstract: We describe an application of an encoder-decoder recurrent neural network\n",
            "with LSTM units and attention to generating headlines from the text of news\n",
            "articles. We find that the model is quite effective at concisely paraphrasing\n",
            "news articles. Furthermore, we study how the neural network decides which input\n",
            "words to pay attention to, and specifically we identify the function of the\n",
            "different neurons in a simplified attention mechanism. Interestingly, our\n",
            "simplified attention mechanism performs better that the more complex attention\n",
            "mechanism on a held out set of articles.\n",
            "Extracted Text:  furthermore study neural network decides input words pay attention specifically identify function different neurons simplified attention mechanism interestingly simplified attention mechanism performs better complex attention mechanism held set articles describe application encoder decoder recurrent neural network lstm units attention generating headlines text news articles find model quite effective concisely paraphrasing news articles \n",
            "Original title: Generating News Headlines with Recurrent Neural Networks\n",
            "Cleaned summary: generating news with recurrent neural networks \n",
            "Predicted title:  news attention based neural network for news articles\n",
            "\n",
            "\n",
            "Abstract: Despite the success of distributional semantics, composing phrases from word\n",
            "vectors remains an important challenge. Several methods have been tried for\n",
            "benchmark tasks such as sentiment classification, including word vector\n",
            "averaging, matrix-vector approaches based on parsing, and on-the-fly learning\n",
            "of paragraph vectors. Most models usually omit stop words from the composition.\n",
            "Instead of such an yes-no decision, we consider several graded schemes where\n",
            "words are weighted according to their discriminatory relevance with respect to\n",
            "its use in the document (e.g., idf). Some of these methods (particularly\n",
            "tf-idf) are seen to result in a significant improvement in performance over\n",
            "prior state of the art. Further, combining such approaches into an ensemble\n",
            "based on alternate classifiers such as the RNN model, results in an 1.6%\n",
            "performance improvement on the standard IMDB movie review dataset, and a 7.01%\n",
            "improvement on Amazon product reviews. Since these are language free models and\n",
            "can be obtained in an unsupervised manner, they are of interest also for\n",
            "under-resourced languages such as Hindi as well and many more languages. We\n",
            "demonstrate the language free aspects by showing a gain of 12% for two review\n",
            "datasets over earlier results, and also release a new larger dataset for future\n",
            "testing (Singh,2015).\n",
            "Extracted Text:  demonstrate language free aspects showing gain two review datasets earlier results also release new larger dataset future testing instead yes decision consider several graded schemes words weighted according discriminatory relevance respect use document methods seen result significant improvement performance prior state art since language free models obtained unsupervised manner interest also resourced languages hindi well many languages several methods tried benchmark tasks sentiment classification including word vector averaging matrix vector approaches based parsing fly learning paragraph vectors despite success distributional semantics composing phrases word vectors remains important challenge combining approaches ensemble based alternate classifiers rnn model results performance improvement standard imdb movie review dataset improvement amazon product reviews models usually omit stop words composition \n",
            "Original title: Words are not Equal: Graded Weighting Model for building Composite\n",
            "  Document Vectors\n",
            "Cleaned summary: words are not equal graded weighting model for building composite document vectors \n",
            "Predicted title:  unsupervised sentiment analysis using word vectors\n",
            "\n",
            "\n",
            "Abstract: Deep learning has dramatically improved the performance of speech recognition\n",
            "systems through learning hierarchies of features optimized for the task at\n",
            "hand. However, true end-to-end learning, where features are learned directly\n",
            "from waveforms, has only recently reached the performance of hand-tailored\n",
            "representations based on the Fourier transform. In this paper, we detail an\n",
            "approach to use convolutional filters to push past the inherent tradeoff of\n",
            "temporal and frequency resolution that exists for spectral representations. At\n",
            "increased computational cost, we show that increasing temporal resolution via\n",
            "reduced stride and increasing frequency resolution via additional filters\n",
            "delivers significant performance improvements. Further, we find more efficient\n",
            "representations by simultaneously learning at multiple scales, leading to an\n",
            "overall decrease in word error rate on a difficult internal speech test set by\n",
            "20.7% relative to networks with the same number of parameters trained on\n",
            "spectrograms.\n",
            "Extracted Text:  find efficient representations simultaneously learning multiple scales leading overall decrease word error rate difficult internal speech test set relative networks number parameters trained spectrograms deep learning dramatically improved performance speech recognition systems learning hierarchies features optimized task hand however true end end learning features learned directly waveforms recently reached performance hand tailored representations based fourier transform increased computational cost show increasing temporal resolution via reduced stride increasing frequency resolution via additional filters delivers significant performance improvements paper detail approach use convolutional filters push past inherent tradeoff temporal frequency resolution exists spectral representations \n",
            "Original title: Learning Multiscale Features Directly From Waveforms\n",
            "Cleaned summary: learning multiscale features directly from \n",
            "Predicted title:  learning to rank with deep convolutional networks\n",
            "\n",
            "\n",
            "Abstract: We consider the problem of Recognizing Textual Entailment within an\n",
            "Information Retrieval context, where we must simultaneously determine the\n",
            "relevancy as well as degree of entailment for individual pieces of evidence to\n",
            "determine a yes/no answer to a binary natural language question.\n",
            "  We compare several variants of neural networks for sentence embeddings in a\n",
            "setting of decision-making based on evidence of varying relevance. We propose a\n",
            "basic model to integrate evidence for entailment, show that joint training of\n",
            "the sentence embeddings to model relevance and entailment is feasible even with\n",
            "no explicit per-evidence supervision, and show the importance of evaluating\n",
            "strong baselines. We also demonstrate the benefit of carrying over text\n",
            "comprehension model trained on an unrelated task for our small datasets.\n",
            "  Our research is motivated primarily by a new open dataset we introduce,\n",
            "consisting of binary questions and news-based evidence snippets. We also apply\n",
            "the proposed relevance-entailment model on a similar task of ranking\n",
            "multiple-choice test answers, evaluating it on a preliminary dataset of school\n",
            "test questions as well as the standard MCTest dataset, where we improve the\n",
            "neural model state-of-art.\n",
            "Extracted Text:  also apply proposed relevance entailment model similar task ranking multiple choice test answers evaluating preliminary dataset school test questions well standard mctest dataset improve neural model state art propose basic model integrate evidence entailment show joint training sentence embeddings model relevance entailment feasible even explicit per evidence supervision show importance evaluating strong baselines compare several variants neural networks sentence embeddings setting decision making based evidence varying relevance consider problem recognizing textual entailment within information retrieval context must simultaneously determine relevancy well degree entailment individual pieces evidence determine yes answer binary natural language question research motivated primarily new open dataset introduce consisting binary questions news based evidence snippets also demonstrate benefit carrying text comprehension model trained unrelated task small datasets \n",
            "Original title: Joint Learning of Sentence Embeddings for Relevance and Entailment\n",
            "Cleaned summary: joint learning of sentence embeddings for relevance and entailment \n",
            "Predicted title:  neural relation extraction from web\n",
            "\n",
            "\n",
            "Abstract: The dominant approach for many NLP tasks are recurrent neural networks, in\n",
            "particular LSTMs, and convolutional neural networks. However, these\n",
            "architectures are rather shallow in comparison to the deep convolutional\n",
            "networks which have pushed the state-of-the-art in computer vision. We present\n",
            "a new architecture (VDCNN) for text processing which operates directly at the\n",
            "character level and uses only small convolutions and pooling operations. We are\n",
            "able to show that the performance of this model increases with depth: using up\n",
            "to 29 convolutional layers, we report improvements over the state-of-the-art on\n",
            "several public text classification tasks. To the best of our knowledge, this is\n",
            "the first time that very deep convolutional nets have been applied to text\n",
            "processing.\n",
            "Extracted Text:  however architectures rather shallow comparison deep convolutional networks pushed state art computer vision able show performance model increases depth using convolutional layers report improvements state art several public text classification tasks present new architecture text processing operates directly character level uses small convolutions pooling operations best knowledge first time deep convolutional nets applied text processing dominant approach many nlp tasks recurrent neural networks particular lstms convolutional neural networks \n",
            "Original title: Very Deep Convolutional Networks for Text Classification\n",
            "Cleaned summary: very deep convolutional networks for text classification \n",
            "Predicted title:  convolutional neural network for text classification\n",
            "\n",
            "\n",
            "Abstract: In this paper we study different types of Recurrent Neural Networks (RNN) for\n",
            "sequence labeling tasks. We propose two new variants of RNNs integrating\n",
            "improvements for sequence labeling, and we compare them to the more traditional\n",
            "Elman and Jordan RNNs. We compare all models, either traditional or new, on\n",
            "four distinct tasks of sequence labeling: two on Spoken Language Understanding\n",
            "(ATIS and MEDIA); and two of POS tagging for the French Treebank (FTB) and the\n",
            "Penn Treebank (PTB) corpora. The results show that our new variants of RNNs are\n",
            "always more effective than the others.\n",
            "Extracted Text:  compare models either traditional new four distinct tasks sequence labeling two spoken language understanding two pos tagging french treebank penn treebank corpora propose two new variants rnns integrating improvements sequence labeling compare traditional elman jordan rnns results show new variants rnns always effective others paper study different types recurrent neural networks sequence labeling tasks \n",
            "Original title: Improving Recurrent Neural Networks For Sequence Labelling\n",
            "Cleaned summary: improving recurrent neural networks for sequence labelling \n",
            "Predicted title:  recurrent neural network with long term memory\n",
            "\n",
            "\n",
            "Abstract: Recent work on generative modeling of text has found that variational\n",
            "auto-encoders (VAE) incorporating LSTM decoders perform worse than simpler LSTM\n",
            "language models (Bowman et al., 2015). This negative result is so far poorly\n",
            "understood, but has been attributed to the propensity of LSTM decoders to\n",
            "ignore conditioning information from the encoder. In this paper, we experiment\n",
            "with a new type of decoder for VAE: a dilated CNN. By changing the decoder's\n",
            "dilation architecture, we control the effective context from previously\n",
            "generated words. In experiments, we find that there is a trade off between the\n",
            "contextual capacity of the decoder and the amount of encoding information used.\n",
            "We show that with the right decoder, VAE can outperform LSTM language models.\n",
            "We demonstrate perplexity gains on two datasets, representing the first\n",
            "positive experimental result on the use VAE for generative modeling of text.\n",
            "Further, we conduct an in-depth investigation of the use of VAE (with our new\n",
            "decoding architecture) for semi-supervised and unsupervised labeling tasks,\n",
            "demonstrating gains over several strong baselines.\n",
            "Extracted Text:  demonstrate perplexity gains two datasets representing first positive experimental result use vae generative modeling text recent work generative modeling text found variational auto encoders incorporating lstm decoders perform worse simpler lstm language models changing decoder dilation architecture control effective context previously generated words experiments find trade contextual capacity decoder amount encoding information used negative result far poorly understood attributed propensity lstm decoders ignore conditioning information encoder conduct depth investigation use vae semi supervised unsupervised labeling tasks demonstrating gains several strong baselines show right decoder vae outperform lstm language models paper experiment new type decoder vae dilated cnn \n",
            "Original title: Improved Variational Autoencoders for Text Modeling using Dilated\n",
            "  Convolutions\n",
            "Cleaned summary: improved variational autoencoders for text modeling using dilated convolutions \n",
            "Predicted title:  variational autoencoders for sequence labeling\n",
            "\n",
            "\n",
            "Abstract: A simplified speech recognition system that uses the maximum mutual\n",
            "information (MMI) criterion is considered. End-to-end training using gradient\n",
            "descent is suggested, similarly to the training of connectionist temporal\n",
            "classification (CTC). We use an MMI criterion with a simple language model in\n",
            "the training stage, and a standard HMM decoder. Our method compares favorably\n",
            "to CTC in terms of performance, robustness, decoding time, disk footprint and\n",
            "quality of alignments. The good alignments enable the use of a straightforward\n",
            "ensemble method, obtained by simply averaging the predictions of several neural\n",
            "network models, that were trained separately end-to-end. The ensemble method\n",
            "yields a considerable reduction in the word error rate.\n",
            "Extracted Text:  good alignments enable use straightforward ensemble method obtained simply averaging predictions several neural network models trained separately end end simplified speech recognition system uses maximum mutual information criterion considered use mmi criterion simple language model training stage standard hmm decoder method compares favorably ctc terms performance robustness decoding time disk footprint quality alignments end end training using gradient descent suggested similarly training connectionist temporal classification ensemble method yields considerable reduction word error rate \n",
            "Original title: Simplified End-to-End MMI Training and Voting for ASR\n",
            "Cleaned summary: simplified end to end training and voting for asr \n",
            "Predicted title:  ensemble training for neural network language models\n",
            "\n",
            "\n",
            "Abstract: We propose a sequence labeling framework with a secondary training objective,\n",
            "learning to predict surrounding words for every word in the dataset. This\n",
            "language modeling objective incentivises the system to learn general-purpose\n",
            "patterns of semantic and syntactic composition, which are also useful for\n",
            "improving accuracy on different sequence labeling tasks. The architecture was\n",
            "evaluated on a range of datasets, covering the tasks of error detection in\n",
            "learner texts, named entity recognition, chunking and POS-tagging. The novel\n",
            "language modeling objective provided consistent performance improvements on\n",
            "every benchmark, without requiring any additional annotated or unannotated\n",
            "data.\n",
            "Extracted Text:  language modeling objective system learn general purpose patterns semantic syntactic composition also useful improving accuracy different sequence labeling tasks propose sequence labeling framework secondary training objective learning predict surrounding words every word dataset novel language modeling objective provided consistent performance improvements every benchmark without requiring additional annotated unannotated data architecture evaluated range datasets covering tasks error detection learner texts named entity recognition chunking pos tagging \n",
            "Original title: Semi-supervised Multitask Learning for Sequence Labeling\n",
            "Cleaned summary: semi supervised multitask learning for sequence labeling \n",
            "Predicted title:  learning semantic roles for multilingual named entity recognition\n",
            "\n",
            "\n",
            "Abstract: We propose a novel word embedding pre-training approach that exploits writing\n",
            "errors in learners' scripts. We compare our method to previous models that tune\n",
            "the embeddings based on script scores and the discrimination between correct\n",
            "and corrupt word contexts in addition to the generic commonly-used embeddings\n",
            "pre-trained on large corpora. The comparison is achieved by using the\n",
            "aforementioned models to bootstrap a neural network that learns to predict a\n",
            "holistic score for scripts. Furthermore, we investigate augmenting our model\n",
            "with error corrections and monitor the impact on performance. Our results show\n",
            "that our error-oriented approach outperforms other comparable ones which is\n",
            "further demonstrated when training on more data. Additionally, extending the\n",
            "model with corrections provides further performance gains when data sparsity is\n",
            "an issue.\n",
            "Extracted Text:  results show error oriented approach outperforms comparable ones demonstrated training data compare method previous models tune embeddings based script scores discrimination correct corrupt word contexts addition generic commonly used embeddings pre trained large corpora comparison achieved using aforementioned models bootstrap neural network learns predict holistic score scripts furthermore investigate augmenting model error corrections monitor impact performance additionally extending model corrections provides performance gains data sparsity issue propose novel word embedding pre training approach exploits writing errors learners scripts \n",
            "Original title: An Error-Oriented Approach to Word Embedding Pre-Training\n",
            "Cleaned summary: an error oriented approach to word embedding pre training \n",
            "Predicted title:  word embeddings for learning word embeddings\n",
            "\n",
            "\n",
            "Abstract: Speech separation is the task of separating target speech from background\n",
            "interference. Traditionally, speech separation is studied as a signal\n",
            "processing problem. A more recent approach formulates speech separation as a\n",
            "supervised learning problem, where the discriminative patterns of speech,\n",
            "speakers, and background noise are learned from training data. Over the past\n",
            "decade, many supervised separation algorithms have been put forward. In\n",
            "particular, the recent introduction of deep learning to supervised speech\n",
            "separation has dramatically accelerated progress and boosted separation\n",
            "performance. This article provides a comprehensive overview of the research on\n",
            "deep learning based supervised speech separation in the last several years. We\n",
            "first introduce the background of speech separation and the formulation of\n",
            "supervised separation. Then we discuss three main components of supervised\n",
            "separation: learning machines, training targets, and acoustic features. Much of\n",
            "the overview is on separation algorithms where we review monaural methods,\n",
            "including speech enhancement (speech-nonspeech separation), speaker separation\n",
            "(multi-talker separation), and speech dereverberation, as well as\n",
            "multi-microphone techniques. The important issue of generalization, unique to\n",
            "supervised learning, is discussed. This overview provides a historical\n",
            "perspective on how advances are made. In addition, we discuss a number of\n",
            "conceptual issues, including what constitutes the target source.\n",
            "Extracted Text:  recent approach formulates speech separation supervised learning problem discriminative patterns speech speakers background noise learned training data much overview separation algorithms review monaural methods including speech enhancement speaker separation speech well multi microphone techniques article provides comprehensive overview research deep learning based supervised speech separation last several years particular recent introduction deep learning supervised speech separation dramatically accelerated progress boosted separation performance first introduce background speech separation formulation supervised separation discuss three main components supervised separation learning machines training targets acoustic features important issue generalization unique supervised learning discussed traditionally speech separation studied signal processing problem addition discuss number conceptual issues including constitutes target source speech separation task separating target speech background interference \n",
            "Original title: Supervised Speech Separation Based on Deep Learning: An Overview\n",
            "Cleaned summary: supervised speech separation based on deep learning an overview \n",
            "Predicted title:  deep learning for speech enhancement\n",
            "\n",
            "\n",
            "Abstract: Context information plays an important role in human language understanding,\n",
            "and it is also useful for machines to learn vector representations of language.\n",
            "In this paper, we explore an asymmetric encoder-decoder structure for\n",
            "unsupervised context-based sentence representation learning. As a result, we\n",
            "build an encoder-decoder architecture with an RNN encoder and a CNN decoder. We\n",
            "further combine a suite of effective designs to significantly improve model\n",
            "efficiency while also achieving better performance. Our model is trained on two\n",
            "different large unlabeled corpora, and in both cases transferability is\n",
            "evaluated on a set of downstream language understanding tasks. We empirically\n",
            "show that our model is simple and fast while producing rich sentence\n",
            "representations that excel in downstream tasks.\n",
            "Extracted Text:  paper explore asymmetric encoder decoder structure unsupervised context based sentence representation learning context information plays important role human language understanding also useful machines learn vector representations language empirically show model simple fast producing rich sentence representations excel downstream tasks model trained two different large unlabeled corpora cases transferability evaluated set downstream language understanding tasks combine suite effective designs significantly improve model efficiency also achieving better performance result build encoder decoder architecture rnn encoder cnn decoder \n",
            "Original title: Exploring Asymmetric Encoder-Decoder Structure for Context-based\n",
            "  Sentence Representation Learning\n",
            "Cleaned summary: exploring asymmetric encoder decoder structure for context based sentence representation learning \n",
            "Predicted title:  unsupervised learning of natural language representations\n",
            "\n",
            "\n",
            "Abstract: The Convolution Neural Network (CNN) has demonstrated the unique advantage in\n",
            "audio, image and text learning; recently it has also challenged Recurrent\n",
            "Neural Networks (RNNs) with long short-term memory cells (LSTM) in\n",
            "sequence-to-sequence learning, since the computations involved in CNN are\n",
            "easily parallelizable whereas those involved in RNN are mostly sequential,\n",
            "leading to a performance bottleneck. However, unlike RNN, the native CNN lacks\n",
            "the history sensitivity required for sequence transformation; therefore\n",
            "enhancing the sequential order awareness, or position-sensitivity, becomes the\n",
            "key to make CNN the general deep learning model. In this work we introduce an\n",
            "extended CNN model with strengthen position-sensitivity, called PoseNet. A\n",
            "notable feature of PoseNet is the asymmetric treatment of position information\n",
            "in the encoder and the decoder. Experiments shows that PoseNet allows us to\n",
            "improve the accuracy of CNN based sequence-to-sequence learning significantly,\n",
            "achieving around 33-36 BLEU scores on the WMT 2014 English-to-German\n",
            "translation task, and around 44-46 BLEU scores on the English-to-French\n",
            "translation task.\n",
            "Extracted Text:  however unlike rnn native cnn lacks history sensitivity required sequence transformation therefore enhancing sequential order awareness position sensitivity becomes key make cnn general deep learning model convolution neural network demonstrated unique advantage audio image text learning recently also challenged recurrent neural networks long short term memory cells sequence sequence learning since computations involved cnn easily parallelizable whereas involved rnn mostly sequential leading performance bottleneck work introduce extended cnn model strengthen position sensitivity called experiments shows allows improve accuracy cnn based sequence sequence learning significantly achieving around bleu scores wmt english german translation task around bleu scores english french translation task notable feature asymmetric treatment position information encoder decoder \n",
            "Original title: CNN Is All You Need\n",
            "Cleaned summary: cnn is all you need \n",
            "Predicted title:  deep learning for neural machine translation\n",
            "\n",
            "\n",
            "Abstract: It will be shown that according to theorems of K. Menger, every neuron grid\n",
            "if identified with a curve is able to preserve the adopted qualitative\n",
            "structure of a data space. Furthermore, if this identification is made, the\n",
            "neuron grid structure can always be mapped to a subset of a universal neuron\n",
            "grid which is constructable in three space dimensions. Conclusions will be\n",
            "drawn for established neuron grid types as well as neural fields.\n",
            "Extracted Text:  furthermore identification made neuron grid structure always mapped subset universal neuron grid three space dimensions shown according theorems every neuron grid identified curve able preserve adopted qualitative structure data space conclusions drawn established neuron grid types well neural fields \n",
            "Original title: A Note on Topology Preservation in Classification, and the Construction\n",
            "  of a Universal Neuron Grid\n",
            "Cleaned summary: note on topology preservation in classification and the construction of universal neuron grid \n",
            "Predicted title:  on the of spiking neural networks\n",
            "\n",
            "\n",
            "Abstract: This paper deals with the distributed processing in the search for an optimum\n",
            "classification model using evolutionary product unit neural networks. For this\n",
            "distributed search we used a cluster of computers. Our objective is to obtain a\n",
            "more efficient design than those net architectures which do not use a\n",
            "distributed process and which thus result in simpler designs. In order to get\n",
            "the best classification models we use evolutionary algorithms to train and\n",
            "design neural networks, which require a very time consuming computation. The\n",
            "reasons behind the need for this distribution are various. It is complicated to\n",
            "train this type of nets because of the difficulty entailed in determining their\n",
            "architecture due to the complex error surface. On the other hand, the use of\n",
            "evolutionary algorithms involves running a great number of tests with different\n",
            "seeds and parameters, thus resulting in a high computational cost\n",
            "Extracted Text:  hand use evolutionary algorithms involves running great number tests different seeds parameters thus resulting high computational cost order get best classification models use evolutionary algorithms train design neural networks require time consuming computation objective obtain efficient design net architectures use distributed process thus result simpler designs paper deals distributed processing search optimum classification model using evolutionary product unit neural networks reasons behind need distribution various complicated train type nets difficulty entailed determining architecture due complex error surface distributed search used cluster computers \n",
            "Original title: Distribution of the search of evolutionary product unit neural networks\n",
            "  for classification\n",
            "Cleaned summary: distribution of the search of evolutionary product unit neural networks for classification \n",
            "Predicted title:  evolutionary algorithm for the classification of evolutionary algorithm\n",
            "\n",
            "\n",
            "Abstract: The visual systems of many mammals, including humans, is able to integrate\n",
            "the geometric information of visual stimuli and to perform cognitive tasks\n",
            "already at the first stages of the cortical processing. This is thought to be\n",
            "the result of a combination of mechanisms, which include feature extraction at\n",
            "single cell level and geometric processing by means of cells connectivity. We\n",
            "present a geometric model of such connectivities in the space of detected\n",
            "features associated to spatio-temporal visual stimuli, and show how they can be\n",
            "used to obtain low-level object segmentation. The main idea is that of defining\n",
            "a spectral clustering procedure with anisotropic affinities over datasets\n",
            "consisting of embeddings of the visual stimuli into higher dimensional spaces.\n",
            "Neural plausibility of the proposed arguments will be discussed.\n",
            "Extracted Text:  present geometric model connectivities space detected features associated spatio temporal visual stimuli show used obtain low level object segmentation thought result combination mechanisms include feature extraction single cell level geometric processing means cells connectivity visual systems many mammals including humans able integrate geometric information visual stimuli perform cognitive tasks already first stages cortical processing main idea defining spectral clustering procedure anisotropic affinities datasets consisting embeddings visual stimuli higher dimensional spaces neural plausibility proposed arguments discussed \n",
            "Original title: Cortical spatio-temporal dimensionality reduction for visual grouping\n",
            "Cleaned summary: cortical spatio temporal dimensionality reduction for visual grouping \n",
            "Predicted title:  visual discovery of spatial objects\n",
            "\n",
            "\n",
            "Abstract: Fuzzy controllers are efficient and interpretable system controllers for\n",
            "continuous state and action spaces. To date, such controllers have been\n",
            "constructed manually or trained automatically either using expert-generated\n",
            "problem-specific cost functions or incorporating detailed knowledge about the\n",
            "optimal control strategy. Both requirements for automatic training processes\n",
            "are not found in most real-world reinforcement learning (RL) problems. In such\n",
            "applications, online learning is often prohibited for safety reasons because\n",
            "online learning requires exploration of the problem's dynamics during policy\n",
            "training. We introduce a fuzzy particle swarm reinforcement learning (FPSRL)\n",
            "approach that can construct fuzzy RL policies solely by training parameters on\n",
            "world models that simulate real system dynamics. These world models are created\n",
            "by employing an autonomous machine learning technique that uses previously\n",
            "generated transition samples of a real system. To the best of our knowledge,\n",
            "this approach is the first to relate self-organizing fuzzy controllers to\n",
            "model-based batch RL. Therefore, FPSRL is intended to solve problems in domains\n",
            "where online learning is prohibited, system dynamics are relatively easy to\n",
            "model from previously generated default policy transition samples, and it is\n",
            "expected that a relatively easily interpretable control policy exists. The\n",
            "efficiency of the proposed approach with problems from such domains is\n",
            "demonstrated using three standard RL benchmarks, i.e., mountain car, cart-pole\n",
            "balancing, and cart-pole swing-up. Our experimental results demonstrate\n",
            "high-performing, interpretable fuzzy policies.\n",
            "Extracted Text:  therefore intended solve problems domains online learning prohibited system dynamics relatively easy model previously generated default policy transition samples expected relatively easily interpretable control policy exists date controllers constructed manually trained automatically either using expert generated problem specific cost functions incorporating detailed knowledge optimal control strategy world models created employing autonomous machine learning technique uses previously generated transition samples real system requirements automatic training processes found real world reinforcement learning problems introduce fuzzy particle swarm reinforcement learning approach construct fuzzy policies solely training parameters world models simulate real system dynamics best knowledge approach first relate self organizing fuzzy controllers model based batch applications online learning often prohibited safety reasons online learning requires exploration problem dynamics policy training experimental results demonstrate high performing interpretable fuzzy policies fuzzy controllers efficient interpretable system controllers continuous state action spaces efficiency proposed approach problems domains demonstrated using three standard benchmarks mountain car cart pole balancing cart pole swing \n",
            "Original title: Particle Swarm Optimization for Generating Interpretable Fuzzy\n",
            "  Reinforcement Learning Policies\n",
            "Cleaned summary: particle swarm optimization for generating interpretable fuzzy reinforcement learning policies \n",
            "Predicted title:  learning to rank with\n",
            "\n",
            "\n",
            "Abstract: A major challenge in designing neural network (NN) systems is to determine\n",
            "the best structure and parameters for the network given the data for the\n",
            "machine learning problem at hand. Examples of parameters are the number of\n",
            "layers and nodes, the learning rates, and the dropout rates. Typically, these\n",
            "parameters are chosen based on heuristic rules and manually fine-tuned, which\n",
            "may be very time-consuming, because evaluating the performance of a single\n",
            "parametrization of the NN may require several hours. This paper addresses the\n",
            "problem of choosing appropriate parameters for the NN by formulating it as a\n",
            "box-constrained mathematical optimization problem, and applying a\n",
            "derivative-free optimization tool that automatically and effectively searches\n",
            "the parameter space. The optimization tool employs a radial basis function\n",
            "model of the objective function (the prediction accuracy of the NN) to\n",
            "accelerate the discovery of configurations yielding high accuracy. Candidate\n",
            "configurations explored by the algorithm are trained to a small number of\n",
            "epochs, and only the most promising candidates receive full training. The\n",
            "performance of the proposed methodology is assessed on benchmark sets and in\n",
            "the context of predicting drug-drug interactions, showing promising results.\n",
            "The optimization tool used in this paper is open-source.\n",
            "Extracted Text:  major challenge designing neural network systems determine best structure parameters network given data machine learning problem hand typically parameters chosen based heuristic rules manually fine tuned may time consuming evaluating performance single parametrization may require several hours paper addresses problem choosing appropriate parameters formulating box constrained mathematical optimization problem applying derivative free optimization tool automatically effectively searches parameter space optimization tool employs radial basis function model objective function accelerate discovery configurations yielding high accuracy optimization tool used paper open source candidate configurations explored algorithm trained small number epochs promising candidates receive full training performance proposed methodology assessed benchmark sets context predicting drug drug interactions showing promising results examples parameters number layers nodes learning rates dropout rates \n",
            "Original title: An effective algorithm for hyperparameter optimization of neural\n",
            "  networks\n",
            "Cleaned summary: an effective algorithm for hyperparameter optimization of neural networks \n",
            "Predicted title:  scalable and accurate protein prediction from single\n",
            "\n",
            "\n",
            "Abstract: Learning to learn is a powerful paradigm for enabling models to learn from\n",
            "data more effectively and efficiently. A popular approach to meta-learning is\n",
            "to train a recurrent model to read in a training dataset as input and output\n",
            "the parameters of a learned model, or output predictions for new test inputs.\n",
            "Alternatively, a more recent approach to meta-learning aims to acquire deep\n",
            "representations that can be effectively fine-tuned, via standard gradient\n",
            "descent, to new tasks. In this paper, we consider the meta-learning problem\n",
            "from the perspective of universality, formalizing the notion of learning\n",
            "algorithm approximation and comparing the expressive power of the\n",
            "aforementioned recurrent models to the more recent approaches that embed\n",
            "gradient descent into the meta-learner. In particular, we seek to answer the\n",
            "following question: does deep representation combined with standard gradient\n",
            "descent have sufficient capacity to approximate any learning algorithm? We find\n",
            "that this is indeed true, and further find, in our experiments, that\n",
            "gradient-based meta-learning consistently leads to learning strategies that\n",
            "generalize more widely compared to those represented by recurrent models.\n",
            "Extracted Text:  alternatively recent approach meta learning aims acquire deep representations effectively fine tuned via standard gradient descent new tasks find indeed true find experiments gradient based meta learning consistently leads learning strategies generalize widely compared represented recurrent models particular seek answer following question deep representation combined standard gradient descent sufficient capacity approximate learning algorithm popular approach meta learning train recurrent model read training dataset input output parameters learned model output predictions new test inputs paper consider meta learning problem perspective universality formalizing notion learning algorithm approximation comparing expressive power aforementioned recurrent models recent approaches embed gradient descent meta learner learning learn powerful paradigm enabling models learn data effectively efficiently \n",
            "Original title: Meta-Learning and Universality: Deep Representations and Gradient\n",
            "  Descent can Approximate any Learning Algorithm\n",
            "Cleaned summary: meta learning and universality deep representations and gradient descent can approximate any learning algorithm \n",
            "Predicted title:  learning deep learning with stochastic gradient descent\n",
            "\n",
            "\n",
            "Abstract: Ordinal regression is an important type of learning, which has properties of\n",
            "both classification and regression. Here we describe a simple and effective\n",
            "approach to adapt a traditional neural network to learn ordinal categories. Our\n",
            "approach is a generalization of the perceptron method for ordinal regression.\n",
            "On several benchmark datasets, our method (NNRank) outperforms a neural network\n",
            "classification method. Compared with the ordinal regression methods using\n",
            "Gaussian processes and support vector machines, NNRank achieves comparable\n",
            "performance. Moreover, NNRank has the advantages of traditional neural\n",
            "networks: learning in both online and batch modes, handling very large training\n",
            "datasets, and making rapid predictions. These features make NNRank a useful and\n",
            "complementary tool for large-scale data processing tasks such as information\n",
            "retrieval, web page ranking, collaborative filtering, and protein ranking in\n",
            "Bioinformatics.\n",
            "Extracted Text:  compared ordinal regression methods using gaussian processes support vector machines achieves comparable performance describe simple effective approach adapt traditional neural network learn ordinal categories several benchmark datasets method outperforms neural network classification method ordinal regression important type learning properties classification regression moreover advantages traditional neural networks learning online batch modes handling large training datasets making rapid predictions features make useful complementary tool large scale data processing tasks information retrieval web page ranking collaborative filtering protein ranking bioinformatics approach generalization perceptron method ordinal regression \n",
            "Original title: A neural network approach to ordinal regression\n",
            "Cleaned summary: neural network approach to ordinal regression \n",
            "Predicted title:  learning to rank with neural networks\n",
            "\n",
            "\n",
            "Abstract: The problem of autonomous navigation is one of the basic problems for\n",
            "robotics. Although, in general, it may be challenging when an autonomous\n",
            "vehicle is placed into partially observable domain. In this paper we consider\n",
            "simplistic environment model and introduce a navigation algorithm based on\n",
            "Learning Classifier System.\n",
            "Extracted Text:  problem autonomous navigation one basic problems robotics paper consider simplistic environment model introduce navigation algorithm based learning classifier system although general may challenging autonomous vehicle placed partially observable domain \n",
            "Original title: A genetic algorithm for autonomous navigation in partially observable\n",
            "  domain\n",
            "Cleaned summary: genetic algorithm for autonomous navigation in partially observable domain \n",
            "Predicted title:  robot navigation with robot robot\n",
            "\n",
            "\n",
            "Abstract: There exists a theory of a single general-purpose learning algorithm which\n",
            "could explain the principles of its operation. This theory assumes that the\n",
            "brain has some initial rough architecture, a small library of simple innate\n",
            "circuits which are prewired at birth and proposes that all significant mental\n",
            "algorithms can be learned. Given current understanding and observations, this\n",
            "paper reviews and lists the ingredients of such an algorithm from both\n",
            "architectural and functional perspectives.\n",
            "Extracted Text:  theory assumes brain initial rough architecture small library simple innate circuits birth proposes significant mental algorithms learned exists theory single general purpose learning algorithm could explain principles operation given current understanding observations paper reviews lists ingredients algorithm architectural functional perspectives \n",
            "Original title: Towards Machine Intelligence\n",
            "Cleaned summary: towards machine intelligence \n",
            "Predicted title:  on the of the\n",
            "\n",
            "\n",
            "Abstract: The problem of Learning from Demonstration is targeted at learning to perform\n",
            "tasks based on observed examples. One approach to Learning from Demonstration\n",
            "is Inverse Reinforcement Learning, in which actions are observed to infer\n",
            "rewards. This work combines a feature based state evaluation approach to\n",
            "Inverse Reinforcement Learning with neuroevolution, a paradigm for modifying\n",
            "neural networks based on their performance on a given task. Neural networks are\n",
            "used to learn from a demonstrated expert policy and are evolved to generate a\n",
            "policy similar to the demonstration. The algorithm is discussed and evaluated\n",
            "against competitive feature-based Inverse Reinforcement Learning approaches. At\n",
            "the cost of execution time, neural networks allow for non-linear combinations\n",
            "of features in state evaluations. These valuations may correspond to state\n",
            "value or state reward. This results in better correspondence to observed\n",
            "examples as opposed to using linear combinations. This work also extends\n",
            "existing work on Bayesian Non-Parametric Feature Construction for Inverse\n",
            "Reinforcement Learning by using non-linear combinations of intermediate data to\n",
            "improve performance. The algorithm is observed to be specifically suitable for\n",
            "a linearly solvable non-deterministic Markov Decision Processes in which\n",
            "multiple rewards are sparsely scattered in state space. A conclusive\n",
            "performance hierarchy between evaluated algorithms is presented.\n",
            "Extracted Text:  work combines feature based state evaluation approach inverse reinforcement learning neuroevolution paradigm modifying neural networks based performance given task work also extends existing work bayesian non parametric feature construction inverse reinforcement learning using non linear combinations intermediate data improve performance cost execution time neural networks allow non linear combinations features state evaluations problem learning demonstration targeted learning perform tasks based observed examples algorithm discussed evaluated competitive feature based inverse reinforcement learning approaches results better correspondence observed examples opposed using linear combinations one approach learning demonstration inverse reinforcement learning actions observed infer rewards neural networks used learn demonstrated expert policy evolved generate policy similar demonstration algorithm observed specifically suitable linearly solvable non deterministic markov decision processes multiple rewards sparsely scattered state space conclusive performance hierarchy evaluated algorithms presented \n",
            "Original title: Neuroevolution-Based Inverse Reinforcement Learning\n",
            "Cleaned summary: based inverse reinforcement learning \n",
            "Predicted title:  bayesian reinforcement learning with the decision making\n",
            "\n",
            "\n",
            "Abstract: We describe a neural attention model with a learnable retinal sampling\n",
            "lattice. The model is trained on a visual search task requiring the\n",
            "classification of an object embedded in a visual scene amidst background\n",
            "distractors using the smallest number of fixations. We explore the tiling\n",
            "properties that emerge in the model's retinal sampling lattice after training.\n",
            "Specifically, we show that this lattice resembles the eccentricity dependent\n",
            "sampling lattice of the primate retina, with a high resolution region in the\n",
            "fovea surrounded by a low resolution periphery. Furthermore, we find conditions\n",
            "where these emergent properties are amplified or eliminated providing clues to\n",
            "their function.\n",
            "Extracted Text:  explore tiling properties emerge model retinal sampling lattice training model trained visual search task requiring classification object embedded visual scene amidst background distractors using smallest number fixations furthermore find conditions emergent properties amplified eliminated providing clues function describe neural attention model learnable retinal sampling lattice specifically show lattice resembles eccentricity dependent sampling lattice primate retina high resolution region fovea surrounded low resolution periphery \n",
            "Original title: Emergence of foveal image sampling from learning to attend in visual\n",
            "  scenes\n",
            "Cleaned summary: emergence of image sampling from learning to attend in visual scenes \n",
            "Predicted title:  learning to rank with\n",
            "\n",
            "\n",
            "Abstract: Reason and inference require process as well as memory skills by humans.\n",
            "Neural networks are able to process tasks like image recognition (better than\n",
            "humans) but in memory aspects are still limited (by attention mechanism, size).\n",
            "Recurrent Neural Network (RNN) and it's modified version LSTM are able to solve\n",
            "small memory contexts, but as context becomes larger than a threshold, it is\n",
            "difficult to use them. The Solution is to use large external memory. Still, it\n",
            "poses many challenges like, how to train neural networks for discrete memory\n",
            "representation, how to describe long term dependencies in sequential data etc.\n",
            "Most prominent neural architectures for such tasks are Memory networks:\n",
            "inference components combined with long term memory and Neural Turing Machines:\n",
            "neural networks using external memory resources. Also, additional techniques\n",
            "like attention mechanism, end to end gradient descent on discrete memory\n",
            "representation are needed to support these solutions. Preliminary results of\n",
            "above neural architectures on simple algorithms (sorting, copying) and Question\n",
            "Answering (based on story, dialogs) application are comparable with the state\n",
            "of the art. In this paper, I explain these architectures (in general), the\n",
            "additional techniques used and the results of their application.\n",
            "Extracted Text:  neural networks able process tasks like image recognition memory aspects still limited still poses many challenges like train neural networks discrete memory representation describe long term dependencies sequential data etc recurrent neural network modified version lstm able solve small memory contexts context becomes larger threshold difficult use also additional techniques like attention mechanism end end gradient descent discrete memory representation needed support solutions reason inference require process well memory skills humans paper explain architectures additional techniques used results application prominent neural architectures tasks memory networks inference components combined long term memory neural turing machines neural networks using external memory resources solution use large external memory preliminary results neural architectures simple algorithms question answering application comparable state art \n",
            "Original title: Survey of reasoning using Neural networks\n",
            "Cleaned summary: survey of reasoning using neural networks \n",
            "Predicted title:  neural architectures for neural machine reading\n",
            "\n",
            "\n",
            "Abstract: Recommendation algorithms that incorporate techniques from deep learning are\n",
            "becoming increasingly popular. Due to the structure of the data coming from\n",
            "recommendation domains (i.e., one-hot-encoded vectors of item preferences),\n",
            "these algorithms tend to have large input and output dimensionalities that\n",
            "dominate their overall size. This makes them difficult to train, due to the\n",
            "limited memory of graphical processing units, and difficult to deploy on mobile\n",
            "devices with limited hardware. To address these difficulties, we propose Bloom\n",
            "embeddings, a compression technique that can be applied to the input and output\n",
            "of neural network models dealing with sparse high-dimensional binary-coded\n",
            "instances. Bloom embeddings are computationally efficient, and do not seriously\n",
            "compromise the accuracy of the model up to 1/5 compression ratios. In some\n",
            "cases, they even improve over the original accuracy, with relative increases up\n",
            "to 12%. We evaluate Bloom embeddings on 7 data sets and compare it against 4\n",
            "alternative methods, obtaining favorable results. We also discuss a number of\n",
            "further advantages of Bloom embeddings, such as 'on-the-fly' constant-time\n",
            "operation, zero or marginal space requirements, training time speedups, or the\n",
            "fact that they do not require any change to the core model architecture or\n",
            "training configuration.\n",
            "Extracted Text:  due structure data coming recommendation domains algorithms tend large input output dimensionalities dominate overall size also discuss number advantages bloom embeddings fly constant time operation zero marginal space requirements training time speedups fact require change core model architecture training configuration address difficulties propose bloom embeddings compression technique applied input output neural network models dealing sparse high dimensional binary coded instances cases even improve original accuracy relative increases makes difficult train due limited memory graphical processing units difficult deploy mobile devices limited hardware recommendation algorithms incorporate techniques deep learning becoming increasingly popular evaluate bloom embeddings data sets compare alternative methods obtaining favorable results bloom embeddings computationally efficient seriously compromise accuracy model compression ratios \n",
            "Original title: Getting deep recommenders fit: Bloom embeddings for sparse binary\n",
            "  input/output networks\n",
            "Cleaned summary: getting deep fit embeddings for sparse binary input output networks \n",
            "Predicted title:  learning to rank with recurrent neural networks\n",
            "\n",
            "\n",
            "Abstract: A population-based optimization algorithm was designed, inspired by two main\n",
            "thinking modes in philosophy, both based on dialectic concept and\n",
            "thesis-antithesis paradigm. They impose two different kinds of dialectics.\n",
            "Idealistic and materialistic antitheses are formulated as optimization models.\n",
            "Based on the models, the population is coordinated for dialectical\n",
            "interactions. At the population-based context, the formulated optimization\n",
            "models are reduced to a simple detection problem for each thinker (particle).\n",
            "According to the assigned thinking mode to each thinker and her/his\n",
            "measurements of corresponding dialectic with other candidate particles, they\n",
            "deterministically decide to interact with a thinker in maximum dialectic with\n",
            "their theses. The position of a thinker at maximum dialectic is known as an\n",
            "available antithesis among the existing solutions. The dialectical interactions\n",
            "at each ideological community are distinguished by meaningful distributions of\n",
            "step-sizes for each thinking mode. In fact, the thinking modes are regarded as\n",
            "exploration and exploitation elements of the proposed algorithm. The result is\n",
            "a delicate balance without any requirement for adjustment of step-size\n",
            "coefficients. Main parameter of the proposed algorithm is the number of\n",
            "particles appointed to each thinking modes, or equivalently for each kind of\n",
            "motions. An additional integer parameter is defined to boost the stability of\n",
            "the final algorithm in some particular problems. The proposed algorithm is\n",
            "evaluated by a testbed of 12 single-objective continuous benchmark functions.\n",
            "Moreover, its performance and speed were highlighted in sparse reconstruction\n",
            "and antenna selection problems, at the context of compressed sensing and\n",
            "massive MIMO, respectively. The results indicate fast and efficient performance\n",
            "in comparison with well-known evolutionary algorithms and dedicated\n",
            "state-of-the-art algorithms.\n",
            "Extracted Text:  population based context formulated optimization models reduced simple detection problem fact thinking modes regarded exploration exploitation elements proposed algorithm population based optimization algorithm designed inspired two main thinking modes philosophy based concept thesis paradigm position maximum known available among existing solutions results indicate fast efficient performance comparison well known evolutionary algorithms dedicated state art algorithms main parameter proposed algorithm number particles thinking modes equivalently kind motions additional integer parameter defined boost stability final algorithm particular problems dialectical interactions ideological community distinguished meaningful distributions step sizes thinking mode according assigned thinking mode measurements corresponding candidate particles deterministically decide interact maximum theses proposed algorithm evaluated testbed single objective continuous benchmark functions \n",
            "Original title: Ideological Sublations: Resolution of Dialectic in Population-based\n",
            "  Optimization\n",
            "Cleaned summary: resolution of in population based optimization \n",
            "Predicted title:  evolutionary optimization for the design of optimization problems\n",
            "\n",
            "\n",
            "Abstract: The rapid advances in e-commerce and Web 2.0 technologies have greatly\n",
            "increased the impact of commercial advertisements on the general public. As a\n",
            "key enabling technology, a multitude of recommender systems exists which\n",
            "analyzes user features and browsing patterns to recommend appealing\n",
            "advertisements to users. In this work, we seek to study the characteristics or\n",
            "attributes that characterize an effective advertisement and recommend a useful\n",
            "set of features to aid the designing and production processes of commercial\n",
            "advertisements. We analyze the temporal patterns from multimedia content of\n",
            "advertisement videos including auditory, visual and textual components, and\n",
            "study their individual roles and synergies in the success of an advertisement.\n",
            "The objective of this work is then to measure the effectiveness of an\n",
            "advertisement, and to recommend a useful set of features to advertisement\n",
            "designers to make it more successful and approachable to users. Our proposed\n",
            "framework employs the signal processing technique of cross modality feature\n",
            "learning where data streams from different components are employed to train\n",
            "separate neural network models and are then fused together to learn a shared\n",
            "representation. Subsequently, a neural network model trained on this joint\n",
            "feature embedding representation is utilized as a classifier to predict\n",
            "advertisement effectiveness. We validate our approach using subjective ratings\n",
            "from a dedicated user study, the sentiment strength of online viewer comments,\n",
            "and a viewer opinion metric of the ratio of the Likes and Views received by\n",
            "each advertisement from an online platform.\n",
            "Extracted Text:  work seek study characteristics attributes characterize effective advertisement recommend useful set features aid designing production processes commercial advertisements objective work measure effectiveness advertisement recommend useful set features advertisement designers make successful approachable users proposed framework employs signal processing technique cross modality feature learning data streams different components employed train separate neural network models fused together learn shared representation analyze temporal patterns multimedia content advertisement videos including auditory visual textual components study individual roles synergies success advertisement key enabling technology multitude recommender systems exists analyzes user features browsing patterns recommend appealing advertisements users subsequently neural network model trained joint feature embedding representation utilized classifier predict advertisement effectiveness validate approach using subjective ratings dedicated user study sentiment strength online viewer comments viewer opinion metric ratio likes views received advertisement online platform rapid advances commerce web technologies greatly increased impact commercial advertisements general public \n",
            "Original title: Multimodal Content Analysis for Effective Advertisements on YouTube\n",
            "Cleaned summary: multimodal content analysis for effective on youtube \n",
            "Predicted title:  sentiment analysis of online reviews using neural network\n",
            "\n",
            "\n",
            "Abstract: The paper introduces the Hidden Tree Markov Network (HTN), a\n",
            "neuro-probabilistic hybrid fusing the representation power of generative models\n",
            "for trees with the incremental and discriminative learning capabilities of\n",
            "neural networks. We put forward a modular architecture in which multiple\n",
            "generative models of limited complexity are trained to learn structural feature\n",
            "detectors whose outputs are then combined and integrated by neural layers at a\n",
            "later stage. In this respect, the model is both deep, thanks to the unfolding\n",
            "of the generative models on the input structures, as well as wide, given the\n",
            "potentially large number of generative modules that can be trained in parallel.\n",
            "Experimental results show that the proposed approach can outperform\n",
            "state-of-the-art syntactic kernels as well as generative kernels built on the\n",
            "same probabilistic model as the HTN.\n",
            "Extracted Text:  put forward modular architecture multiple generative models limited complexity trained learn structural feature detectors whose outputs combined integrated neural layers later stage respect model deep thanks unfolding generative models input structures well wide given potentially large number generative modules trained parallel experimental results show proposed approach outperform state art syntactic kernels well generative kernels built probabilistic model htn paper introduces hidden tree markov network neuro probabilistic hybrid fusing representation power generative models trees incremental discriminative learning capabilities neural networks \n",
            "Original title: Hidden Tree Markov Networks: Deep and Wide Learning for Structured Data\n",
            "Cleaned summary: hidden tree markov networks deep and wide learning for structured data \n",
            "Predicted title:  generative model for learning generative models\n",
            "\n",
            "\n",
            "Abstract: The hard problem in artificial intelligence asks how the shuffling of\n",
            "syntactical symbols in a program can lead to systems which experience semantics\n",
            "and qualia. We address this question in three stages. First, we introduce a new\n",
            "class of human semantic symbols which appears when unexpected and drastic\n",
            "environmental change causes humans to become surprised, confused, uncertain,\n",
            "and in extreme cases, unresponsive, passive and dysfunctional. For this class\n",
            "of symbols, pre-learned programs become inoperative so these syntactical\n",
            "programs cannot be the source of experienced qualia. Second, we model the\n",
            "dysfunctional human response to a radically changed environment as being the\n",
            "natural response of any learning machine facing novel inputs from well outside\n",
            "its previous training set. In this situation, learning machines are unable to\n",
            "extract information from their input and will typically enter a dynamical state\n",
            "characterized by null outputs and a lack of response. This state immediately\n",
            "predicts and explains the characteristics of the semantic experiences of humans\n",
            "in similar circumstances. In the third stage, we consider learning machines\n",
            "trained to implement multiple functions in simple sequential programs using\n",
            "environmental data to specify subroutine names, control flow instructions,\n",
            "memory calls, and so on. Drastic change in any of these environmental inputs\n",
            "can again lead to inoperative programs. By examining changes specific to people\n",
            "or locations we can model human cognitive symbols featuring these dependencies,\n",
            "such as attachment and grief. Our approach links known dynamical machines\n",
            "states with human qualia and thus offers new insight into the hard problem of\n",
            "artificial intelligence.\n",
            "Extracted Text:  second model human response radically changed environment natural response learning machine facing novel inputs well outside previous training set approach links known dynamical machines states human qualia thus offers new insight hard problem artificial intelligence third stage consider learning machines trained implement multiple functions simple sequential programs using environmental data specify subroutine names control flow instructions memory calls situation learning machines unable extract information input typically enter dynamical state characterized null outputs lack response first introduce new class human semantic symbols appears unexpected drastic environmental change causes humans become surprised confused uncertain extreme cases passive hard problem artificial intelligence asks shuffling syntactical symbols program lead systems experience semantics qualia state immediately predicts explains characteristics semantic experiences humans similar circumstances class symbols pre learned programs become syntactical programs cannot source experienced qualia examining changes specific people locations model human cognitive symbols featuring dependencies attachment drastic change environmental inputs lead programs \n",
            "Original title: Null Dynamical State Models of Human Cognitive Dysfunction\n",
            "Cleaned summary: null dynamical state models of human cognitive \n",
            "Predicted title:  the sp theory of intelligence\n",
            "\n",
            "\n",
            "Abstract: Common-sense physical reasoning is an essential ingredient for any\n",
            "intelligent agent operating in the real-world. For example, it can be used to\n",
            "simulate the environment, or to infer the state of parts of the world that are\n",
            "currently unobserved. In order to match real-world conditions this causal\n",
            "knowledge must be learned without access to supervised data. To address this\n",
            "problem we present a novel method that learns to discover objects and model\n",
            "their physical interactions from raw visual images in a purely\n",
            "\\emph{unsupervised} fashion. It incorporates prior knowledge about the\n",
            "compositional nature of human perception to factor interactions between\n",
            "object-pairs and learn efficiently. On videos of bouncing balls we show the\n",
            "superior modelling capabilities of our method compared to other unsupervised\n",
            "neural approaches that do not incorporate such prior knowledge. We demonstrate\n",
            "its ability to handle occlusion and show that it can extrapolate learned\n",
            "knowledge to scenes with different numbers of objects.\n",
            "Extracted Text:  address problem present novel method learns discover objects model physical interactions raw visual images purely emph unsupervised fashion incorporates prior knowledge compositional nature human perception factor interactions object pairs learn efficiently demonstrate ability handle occlusion show extrapolate learned knowledge scenes different numbers objects order match real world conditions causal knowledge must learned without access supervised data common sense physical reasoning essential ingredient intelligent agent operating real world example used simulate environment infer state parts world currently unobserved videos bouncing balls show superior modelling capabilities method compared unsupervised neural approaches incorporate prior knowledge \n",
            "Original title: Relational Neural Expectation Maximization: Unsupervised Discovery of\n",
            "  Objects and their Interactions\n",
            "Cleaned summary: relational neural expectation maximization unsupervised discovery of objects and their interactions \n",
            "Predicted title:  learning to learn with\n",
            "\n",
            "\n",
            "Abstract: In events that are composed by many activities, there is a problem that\n",
            "involves retrieve and management the information of visitors that are visiting\n",
            "the activities. This management is crucial to find some activities that are\n",
            "drawing attention of visitors; identify an ideal positioning for activities;\n",
            "which path is more frequented by visitors. In this work, these features are\n",
            "studied using Complex Network theory. For the beginning, an artificial database\n",
            "was generated to study the mentioned features. Secondly, this work shows a\n",
            "method to optimize the event structure that is better than a random method and\n",
            "a recommendation system that achieves ~95% of accuracy.\n",
            "Extracted Text:  events composed many activities problem involves retrieve management information visitors visiting activities work features studied using complex network theory beginning artificial database generated study mentioned features management crucial find activities drawing attention visitors identify ideal positioning activities path visitors secondly work shows method optimize event structure better random method recommendation system achieves accuracy \n",
            "Original title: A Bayesian Model for Activities Recommendation and Event Structure\n",
            "  Optimization Using Visitors Tracking\n",
            "Cleaned summary: bayesian model for activities recommendation and event structure optimization using tracking \n",
            "Predicted title:  detecting and explaining time in time series using artificial neural networks\n",
            "\n",
            "\n",
            "Abstract: Multilayer bootstrap network builds a gradually narrowed multilayer nonlinear\n",
            "network from bottom up for unsupervised nonlinear dimensionality reduction.\n",
            "Each layer of the network is a nonparametric density estimator. It consists of\n",
            "a group of k-centroids clusterings. Each clustering randomly selects data\n",
            "points with randomly selected features as its centroids, and learns a one-hot\n",
            "encoder by one-nearest-neighbor optimization. Geometrically, the nonparametric\n",
            "density estimator at each layer projects the input data space to a\n",
            "uniformly-distributed discrete feature space, where the similarity of two data\n",
            "points in the discrete feature space is measured by the number of the nearest\n",
            "centroids they share in common. The multilayer network gradually reduces the\n",
            "nonlinear variations of data from bottom up by building a vast number of\n",
            "hierarchical trees implicitly on the original data space. Theoretically, the\n",
            "estimation error caused by the nonparametric density estimator is proportional\n",
            "to the correlation between the clusterings, both of which are reduced by the\n",
            "randomization steps.\n",
            "Extracted Text:  geometrically nonparametric density estimator layer projects input data space uniformly distributed discrete feature space similarity two data points discrete feature space measured number nearest centroids share common multilayer network gradually reduces nonlinear variations data bottom building vast number hierarchical trees implicitly original data space clustering randomly selects data points randomly selected features centroids learns one hot encoder one nearest neighbor optimization multilayer bootstrap network builds gradually narrowed multilayer nonlinear network bottom unsupervised nonlinear dimensionality reduction theoretically estimation error caused nonparametric density estimator proportional correlation clusterings reduced randomization steps layer network nonparametric density estimator consists group centroids clusterings \n",
            "Original title: Multilayer bootstrap networks\n",
            "Cleaned summary: multilayer bootstrap networks \n",
            "Predicted title:  random forest based nearest neighbor descent for nearest neighbor classification\n",
            "\n",
            "\n",
            "Abstract: Why does Deep Learning work? What representations does it capture? How do\n",
            "higher-order representations emerge? We study these questions from the\n",
            "perspective of group theory, thereby opening a new approach towards a theory of\n",
            "Deep learning.\n",
            "  One factor behind the recent resurgence of the subject is a key algorithmic\n",
            "step called pre-training: first search for a good generative model for the\n",
            "input samples, and repeat the process one layer at a time. We show deeper\n",
            "implications of this simple principle, by establishing a connection with the\n",
            "interplay of orbits and stabilizers of group actions. Although the neural\n",
            "networks themselves may not form groups, we show the existence of {\\em shadow}\n",
            "groups whose elements serve as close approximations.\n",
            "  Over the shadow groups, the pre-training step, originally introduced as a\n",
            "mechanism to better initialize a network, becomes equivalent to a search for\n",
            "features with minimal orbits. Intuitively, these features are in a way the {\\em\n",
            "simplest}. Which explains why a deep learning network learns simple features\n",
            "first. Next, we show how the same principle, when repeated in the deeper\n",
            "layers, can capture higher order representations, and why representation\n",
            "complexity increases as the layers get deeper.\n",
            "Extracted Text:  one factor behind recent resurgence subject key algorithmic step called pre training first search good generative model input samples repeat process one layer time next show principle repeated deeper layers capture higher order representations representation complexity increases layers get deeper although neural networks may form groups show existence shadow groups whose elements serve close approximations shadow groups pre training step originally introduced mechanism better initialize network becomes equivalent search features minimal orbits study questions perspective group theory thereby opening new approach towards theory deep learning show deeper implications simple principle establishing connection interplay orbits group actions explains deep learning network learns simple features first deep learning work higher order representations emerge intuitively features way simplest \n",
            "Original title: Why does Deep Learning work? - A perspective from Group Theory\n",
            "Cleaned summary: why does deep learning work perspective from group theory \n",
            "Predicted title:  deep learning with the neural network\n",
            "\n",
            "\n",
            "Abstract: Deep convolutional neural networks comprise a subclass of deep neural\n",
            "networks (DNN) with a constrained architecture that leverages the spatial and\n",
            "temporal structure of the domain they model. Convolutional networks achieve the\n",
            "best predictive performance in areas such as speech and image recognition by\n",
            "hierarchically composing simple local features into complex models. Although\n",
            "DNNs have been used in drug discovery for QSAR and ligand-based bioactivity\n",
            "predictions, none of these models have benefited from this powerful\n",
            "convolutional architecture. This paper introduces AtomNet, the first\n",
            "structure-based, deep convolutional neural network designed to predict the\n",
            "bioactivity of small molecules for drug discovery applications. We demonstrate\n",
            "how to apply the convolutional concepts of feature locality and hierarchical\n",
            "composition to the modeling of bioactivity and chemical interactions. In\n",
            "further contrast to existing DNN techniques, we show that AtomNet's application\n",
            "of local convolutional filters to structural target information successfully\n",
            "predicts new active molecules for targets with no previously known modulators.\n",
            "Finally, we show that AtomNet outperforms previous docking approaches on a\n",
            "diverse set of benchmarks by a large margin, achieving an AUC greater than 0.9\n",
            "on 57.8% of the targets in the DUDE benchmark.\n",
            "Extracted Text:  contrast existing dnn techniques show application local convolutional filters structural target information successfully predicts new active molecules targets previously known paper introduces first structure based deep convolutional neural network designed predict small molecules drug discovery applications convolutional networks achieve best predictive performance areas speech image recognition hierarchically composing simple local features complex models although dnns used drug discovery qsar ligand based predictions none models benefited powerful convolutional architecture demonstrate apply convolutional concepts feature locality hierarchical composition modeling chemical interactions deep convolutional neural networks comprise subclass deep neural networks constrained architecture leverages spatial temporal structure domain model finally show outperforms previous docking approaches diverse set benchmarks large margin achieving auc greater targets benchmark \n",
            "Original title: AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction\n",
            "  in Structure-based Drug Discovery\n",
            "Cleaned summary: deep convolutional neural network for prediction in structure based drug discovery \n",
            "Predicted title:  convolutional neural network for image classification\n",
            "\n",
            "\n",
            "Abstract: In this paper, we use variational recurrent neural network to investigate the\n",
            "anomaly detection problem on graph time series. The temporal correlation is\n",
            "modeled by the combination of recurrent neural network (RNN) and variational\n",
            "inference (VI), while the spatial information is captured by the graph\n",
            "convolutional network. In order to incorporate external factors, we use feature\n",
            "extractor to augment the transition of latent variables, which can learn the\n",
            "influence of external factors. With the target function as accumulative ELBO,\n",
            "it is easy to extend this model to on-line method. The experimental study on\n",
            "traffic flow data shows the detection capability of the proposed method.\n",
            "Extracted Text:  paper use variational recurrent neural network investigate anomaly detection problem graph time series experimental study traffic flow data shows detection capability proposed method target function accumulative elbo easy extend model line method order incorporate external factors use feature extractor augment transition latent variables learn influence external factors temporal correlation modeled combination recurrent neural network variational inference spatial information captured graph convolutional network \n",
            "Original title: Anomaly Detection on Graph Time Series\n",
            "Cleaned summary: anomaly detection on graph time series \n",
            "Predicted title:  recurrent neural network with structured information for traffic anomaly detection\n",
            "\n",
            "\n",
            "Abstract: We present an alternative to the pseudo-inverse method for determining the\n",
            "hidden to output weight values for Extreme Learning Machines performing\n",
            "classification tasks. The method is based on linear discriminant analysis and\n",
            "provides Bayes optimal single point estimates for the weight values.\n",
            "Extracted Text:  present alternative pseudo inverse method determining hidden output weight values extreme learning machines performing classification tasks method based linear discriminant analysis provides bayes optimal single point estimates weight values \n",
            "Original title: Learning ELM network weights using linear discriminant analysis\n",
            "Cleaned summary: learning elm network weights using linear discriminant analysis \n",
            "Predicted title:  learning to rank with\n",
            "\n",
            "\n",
            "Abstract: Many state-of-the-art results obtained with deep networks are achieved with\n",
            "the largest models that could be trained, and if more computation power was\n",
            "available, we might be able to exploit much larger datasets in order to improve\n",
            "generalization ability. Whereas in learning algorithms such as decision trees\n",
            "the ratio of capacity (e.g., the number of parameters) to computation is very\n",
            "favorable (up to exponentially more parameters than computation), the ratio is\n",
            "essentially 1 for deep neural networks. Conditional computation has been\n",
            "proposed as a way to increase the capacity of a deep neural network without\n",
            "increasing the amount of computation required, by activating some parameters\n",
            "and computation \"on-demand\", on a per-example basis. In this note, we propose a\n",
            "novel parametrization of weight matrices in neural networks which has the\n",
            "potential to increase up to exponentially the ratio of the number of parameters\n",
            "to computation. The proposed approach is based on turning on some parameters\n",
            "(weight matrices) when specific bit patterns of hidden unit activations are\n",
            "obtained. In order to better control for the overfitting that might result, we\n",
            "propose a parametrization that is tree-structured, where each node of the tree\n",
            "corresponds to a prefix of a sequence of sign bits, or gating units, associated\n",
            "with hidden units.\n",
            "Extracted Text:  conditional computation proposed way increase capacity deep neural network without increasing amount computation required activating parameters computation demand per example basis whereas learning algorithms decision trees ratio capacity computation favorable ratio essentially deep neural networks proposed approach based turning parameters specific bit patterns hidden unit activations obtained order better control overfitting might result propose parametrization tree structured node tree corresponds prefix sequence sign bits gating units associated hidden units many state art results obtained deep networks achieved largest models could trained computation power available might able exploit much larger datasets order improve generalization ability note propose novel parametrization weight matrices neural networks potential increase exponentially ratio number parameters computation \n",
            "Original title: Exponentially Increasing the Capacity-to-Computation Ratio for\n",
            "  Conditional Computation in Deep Learning\n",
            "Cleaned summary: exponentially increasing the capacity to computation ratio for conditional computation in deep learning \n",
            "Predicted title:  tree structured neural networks\n",
            "\n",
            "\n",
            "Abstract: We study the complexity of functions computable by deep feedforward neural\n",
            "networks with piecewise linear activations in terms of the symmetries and the\n",
            "number of linear regions that they have. Deep networks are able to sequentially\n",
            "map portions of each layer's input-space to the same output. In this way, deep\n",
            "models compute functions that react equally to complicated patterns of\n",
            "different inputs. The compositional structure of these functions enables them\n",
            "to re-use pieces of computation exponentially often in terms of the network's\n",
            "depth. This paper investigates the complexity of such compositional maps and\n",
            "contributes new theoretical results regarding the advantage of depth for neural\n",
            "networks with piecewise linear activation functions. In particular, our\n",
            "analysis is not specific to a single family of models, and as an example, we\n",
            "employ it for rectifier and maxout networks. We improve complexity bounds from\n",
            "pre-existing work and investigate the behavior of units in higher layers.\n",
            "Extracted Text:  compositional structure functions enables use pieces computation exponentially often terms network depth paper investigates complexity compositional maps contributes new theoretical results regarding advantage depth neural networks piecewise linear activation functions way deep models compute functions react equally complicated patterns different inputs particular analysis specific single family models example employ rectifier maxout networks improve complexity bounds pre existing work investigate behavior units higher layers deep networks able sequentially map portions layer input space output study complexity functions computable deep feedforward neural networks piecewise linear activations terms symmetries number linear regions \n",
            "Original title: On the Number of Linear Regions of Deep Neural Networks\n",
            "Cleaned summary: on the number of linear regions of deep neural networks \n",
            "Predicted title:  on the of deep learning\n",
            "\n",
            "\n",
            "Abstract: Training deep belief networks (DBNs) requires optimizing a non-convex\n",
            "function with an extremely large number of parameters. Naturally, existing\n",
            "gradient descent (GD) based methods are prone to arbitrarily poor local minima.\n",
            "In this paper, we rigorously show that such local minima can be avoided (upto\n",
            "an approximation error) by using the dropout technique, a widely used heuristic\n",
            "in this domain. In particular, we show that by randomly dropping a few nodes of\n",
            "a one-hidden layer neural network, the training objective function, up to a\n",
            "certain approximation error, decreases by a multiplicative factor.\n",
            "  On the flip side, we show that for training convex empirical risk minimizers\n",
            "(ERM), dropout in fact acts as a \"stabilizer\" or regularizer. That is, a simple\n",
            "dropout based GD method for convex ERMs is stable in the face of arbitrary\n",
            "changes to any one of the training points. Using the above assertion, we show\n",
            "that dropout provides fast rates for generalization error in learning (convex)\n",
            "generalized linear models (GLM). Moreover, using the above mentioned stability\n",
            "properties of dropout, we design dropout based differentially private\n",
            "algorithms for solving ERMs. The learned GLM thus, preserves privacy of each of\n",
            "the individual training points while providing accurate predictions for new\n",
            "test points. Finally, we empirically validate our stability assertions for\n",
            "dropout in the context of convex ERMs and show that surprisingly, dropout\n",
            "significantly outperforms (in terms of prediction accuracy) the L2\n",
            "regularization based methods for several benchmark datasets.\n",
            "Extracted Text:  simple dropout based method convex stable face arbitrary changes one training points using assertion show dropout provides fast rates generalization error learning generalized linear models training deep belief networks requires optimizing non convex function extremely large number parameters particular show randomly dropping nodes one hidden layer neural network training objective function certain approximation error decreases multiplicative factor moreover using mentioned stability properties dropout design dropout based differentially private algorithms solving paper rigorously show local minima avoided using dropout technique widely used heuristic domain finally empirically validate stability assertions dropout context convex show surprisingly dropout significantly outperforms regularization based methods several benchmark datasets flip side show training convex empirical risk minimizers dropout fact acts regularizer learned glm thus preserves privacy individual training points providing accurate predictions new test points naturally existing gradient descent based methods prone arbitrarily poor local minima \n",
            "Original title: To Drop or Not to Drop: Robustness, Consistency and Differential Privacy\n",
            "  Properties of Dropout\n",
            "Cleaned summary: to or not to robustness consistency and differential privacy properties of dropout \n",
            "Predicted title:  gradient descent for training deep networks\n",
            "\n",
            "\n",
            "Abstract: We evaluate the uncertainty quality in neural networks using anomaly\n",
            "detection. We extract uncertainty measures (e.g. entropy) from the predictions\n",
            "of candidate models, use those measures as features for an anomaly detector,\n",
            "and gauge how well the detector differentiates known from unknown classes. We\n",
            "assign higher uncertainty quality to candidate models that lead to better\n",
            "detectors. We also propose a novel method for sampling a variational\n",
            "approximation of a Bayesian neural network, called One-Sample Bayesian\n",
            "Approximation (OSBA). We experiment on two datasets, MNIST and CIFAR10. We\n",
            "compare the following candidate neural network models: Maximum Likelihood,\n",
            "Bayesian Dropout, OSBA, and --- for MNIST --- the standard variational\n",
            "approximation. We show that Bayesian Dropout and OSBA provide better\n",
            "uncertainty information than Maximum Likelihood, and are essentially equivalent\n",
            "to the standard variational approximation, but much faster.\n",
            "Extracted Text:  show bayesian dropout provide better uncertainty information maximum likelihood essentially equivalent standard variational approximation much faster entropy predictions candidate models use measures features anomaly detector gauge well detector differentiates known unknown classes compare following candidate neural network models maximum likelihood bayesian dropout mnist standard variational approximation evaluate uncertainty quality neural networks using anomaly detection assign higher uncertainty quality candidate models lead better detectors also propose novel method sampling variational approximation bayesian neural network called one sample bayesian approximation experiment two datasets mnist cifar extract uncertainty measures \n",
            "Original title: Known Unknowns: Uncertainty Quality in Bayesian Neural Networks\n",
            "Cleaned summary: known uncertainty quality in bayesian neural networks \n",
            "Predicted title:  bayesian variational inference for anomaly detection\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmyLbno9uqSI",
        "colab_type": "text"
      },
      "source": [
        "# BLEU SCORE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4sD8hqTup5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "total_score = 0\n",
        "total_count = 0\n",
        "total_score1 = 0\n",
        "total_count1 = 0\n",
        "\n",
        "for i in range(len(x_val)):\n",
        "  \n",
        "  result_title = decode_sequence(x_val[i].reshape(1,max_text_len))\n",
        "  actual_title = seq2summary(y_val[i])\n",
        "  \n",
        "  score = sentence_bleu([actual_title.split(\" \")],result_title.split(\" \"))\n",
        "  total_score += score\n",
        "  total_count += 1\n",
        "  score = sentence_bleu([x_val_org_title[i].split(\" \")],result_title.split(\" \"))\n",
        "  total_score1 += score\n",
        "  total_count1 += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etro4EDXxOfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "587386f1-7297-44be-f538-85f60a52c458"
      },
      "source": [
        "print(\"Average BLEU Score on validation set (after removal of stopwords from title): \",total_score/total_count)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average BLEU Score on validation set (after removal of stopwords from title):  0.49508788806349663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfIJORuyptTZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aeb7ecd8-cdd8-4a4e-aa79-bc7654ba322a"
      },
      "source": [
        "print(\"Average BLEU Score on validation set (using original titles): \",total_score1/total_count1)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average BLEU Score on validation set (using original titles):  0.19229979038589734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ctnnURlXfF",
        "colab_type": "text"
      },
      "source": [
        "# Saving Models and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL-FwmTz7s4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/NLP/titlegen.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2KTUDxt87jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model.save(\"/content/drive/My Drive/NLP/titlegenPredict.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbAWOxm6FapG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/NLP/ytokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(y_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBpwqfT9JqED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/NLP/xtokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(x_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfE67LHpjOG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}